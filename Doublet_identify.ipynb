{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83853f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfa06c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/mohammads/Downloads/new_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7de6a8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HTO2         4321\n",
       "HTO1         3225\n",
       "HTO5         2067\n",
       "HTO4         1672\n",
       "HTO1_HTO2    1480\n",
       "HTO2_HTO5     937\n",
       "HTO2_HTO4     932\n",
       "HTO1_HTO4     871\n",
       "HTO1_HTO5     776\n",
       "HTO4_HTO5     568\n",
       "HTO1_HTO3     282\n",
       "HTO3_HTO4      79\n",
       "HTO2_HTO3      50\n",
       "HTO3_HTO5      31\n",
       "HTO3           31\n",
       "Name: HTO_classification, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.HTO_classification.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4bbbce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)\n",
    "df[\"HTO_classification.global\"].replace({\"Doublet\" : 1, \"Singlet\":0}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36c6dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['HTO_classification'].str.contains('HTO4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32b350b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalRNA</th>\n",
       "      <th>DetectedGenes</th>\n",
       "      <th>ExpressionCV</th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "      <th>PC_5</th>\n",
       "      <th>PC_6</th>\n",
       "      <th>PC_7</th>\n",
       "      <th>...</th>\n",
       "      <th>UMAP_1</th>\n",
       "      <th>UMAP_2</th>\n",
       "      <th>entropy</th>\n",
       "      <th>MitochondrialExpression</th>\n",
       "      <th>HTO_classification</th>\n",
       "      <th>HTO_classification.global</th>\n",
       "      <th>percent.mito</th>\n",
       "      <th>mito.ribo_ratio</th>\n",
       "      <th>S.Score</th>\n",
       "      <th>G2M.Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>2386</td>\n",
       "      <td>1083</td>\n",
       "      <td>11.552594</td>\n",
       "      <td>-404.196056</td>\n",
       "      <td>0.270596</td>\n",
       "      <td>-15.589438</td>\n",
       "      <td>-7.211173</td>\n",
       "      <td>-22.853344</td>\n",
       "      <td>-22.385460</td>\n",
       "      <td>-17.353918</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.788362</td>\n",
       "      <td>1.673063</td>\n",
       "      <td>6.346444</td>\n",
       "      <td>146</td>\n",
       "      <td>HTO1_HTO4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061190</td>\n",
       "      <td>0.190850</td>\n",
       "      <td>-0.182994</td>\n",
       "      <td>-0.182994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>1104</td>\n",
       "      <td>671</td>\n",
       "      <td>14.946237</td>\n",
       "      <td>-550.626081</td>\n",
       "      <td>-17.047074</td>\n",
       "      <td>-19.996038</td>\n",
       "      <td>47.658683</td>\n",
       "      <td>16.296808</td>\n",
       "      <td>-89.258889</td>\n",
       "      <td>-67.618935</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.853453</td>\n",
       "      <td>1.414684</td>\n",
       "      <td>6.050342</td>\n",
       "      <td>160</td>\n",
       "      <td>HTO4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.658436</td>\n",
       "      <td>-0.256485</td>\n",
       "      <td>-0.512970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>1143</td>\n",
       "      <td>636</td>\n",
       "      <td>12.589573</td>\n",
       "      <td>437.183048</td>\n",
       "      <td>31.621254</td>\n",
       "      <td>-9.279668</td>\n",
       "      <td>-18.084306</td>\n",
       "      <td>51.432794</td>\n",
       "      <td>-14.306720</td>\n",
       "      <td>-4.107001</td>\n",
       "      <td>...</td>\n",
       "      <td>7.604406</td>\n",
       "      <td>-0.241866</td>\n",
       "      <td>6.018855</td>\n",
       "      <td>114</td>\n",
       "      <td>HTO4_HTO5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099738</td>\n",
       "      <td>0.273381</td>\n",
       "      <td>-0.253017</td>\n",
       "      <td>-0.577201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13929</th>\n",
       "      <td>1142</td>\n",
       "      <td>623</td>\n",
       "      <td>14.162144</td>\n",
       "      <td>-508.622326</td>\n",
       "      <td>51.027042</td>\n",
       "      <td>-19.757319</td>\n",
       "      <td>-7.031302</td>\n",
       "      <td>29.212541</td>\n",
       "      <td>67.953207</td>\n",
       "      <td>-7.109508</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.260069</td>\n",
       "      <td>-1.849893</td>\n",
       "      <td>5.970239</td>\n",
       "      <td>52</td>\n",
       "      <td>HTO2_HTO4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045534</td>\n",
       "      <td>0.218487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.651354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14717</th>\n",
       "      <td>1334</td>\n",
       "      <td>632</td>\n",
       "      <td>13.462277</td>\n",
       "      <td>231.347755</td>\n",
       "      <td>-170.692434</td>\n",
       "      <td>38.517599</td>\n",
       "      <td>-21.957237</td>\n",
       "      <td>36.296779</td>\n",
       "      <td>-7.430320</td>\n",
       "      <td>-6.727573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780703</td>\n",
       "      <td>-8.057266</td>\n",
       "      <td>5.916535</td>\n",
       "      <td>135</td>\n",
       "      <td>HTO2_HTO4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101199</td>\n",
       "      <td>0.231561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.237736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TotalRNA  DetectedGenes  ExpressionCV        PC_1        PC_2  \\\n",
       "4025       2386           1083     11.552594 -404.196056    0.270596   \n",
       "5015       1104            671     14.946237 -550.626081  -17.047074   \n",
       "6355       1143            636     12.589573  437.183048   31.621254   \n",
       "13929      1142            623     14.162144 -508.622326   51.027042   \n",
       "14717      1334            632     13.462277  231.347755 -170.692434   \n",
       "\n",
       "            PC_3       PC_4       PC_5       PC_6       PC_7  ...     UMAP_1  \\\n",
       "4025  -15.589438  -7.211173 -22.853344 -22.385460 -17.353918  ...  -6.788362   \n",
       "5015  -19.996038  47.658683  16.296808 -89.258889 -67.618935  ...  -4.853453   \n",
       "6355   -9.279668 -18.084306  51.432794 -14.306720  -4.107001  ...   7.604406   \n",
       "13929 -19.757319  -7.031302  29.212541  67.953207  -7.109508  ... -11.260069   \n",
       "14717  38.517599 -21.957237  36.296779  -7.430320  -6.727573  ...  -0.780703   \n",
       "\n",
       "         UMAP_2   entropy  MitochondrialExpression  HTO_classification  \\\n",
       "4025   1.673063  6.346444                      146           HTO1_HTO4   \n",
       "5015   1.414684  6.050342                      160                HTO4   \n",
       "6355  -0.241866  6.018855                      114           HTO4_HTO5   \n",
       "13929 -1.849893  5.970239                       52           HTO2_HTO4   \n",
       "14717 -8.057266  5.916535                      135           HTO2_HTO4   \n",
       "\n",
       "       HTO_classification.global  percent.mito  mito.ribo_ratio   S.Score  \\\n",
       "4025                           1      0.061190         0.190850 -0.182994   \n",
       "5015                           0      0.144928         0.658436 -0.256485   \n",
       "6355                           1      0.099738         0.273381 -0.253017   \n",
       "13929                          1      0.045534         0.218487  0.000000   \n",
       "14717                          1      0.101199         0.231561  0.000000   \n",
       "\n",
       "       G2M.Score  \n",
       "4025   -0.182994  \n",
       "5015   -0.512970  \n",
       "6355   -0.577201  \n",
       "13929  -0.651354  \n",
       "14717  -0.237736  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_test.drop(\"Unnamed: 0\", axis = \"columns\")\n",
    "X_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c209902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(\"HTO_classification\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8aa97277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(\"HTO_classification.global\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595eb58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ac19fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[~df['HTO_classification'].str.contains('HTO4')]\n",
    "X_train = df_train.drop(\"Unnamed: 0\", axis = \"columns\")\n",
    "X_train = X_train.drop(\"HTO_classification\", axis = \"columns\")\n",
    "X_train = X_train.drop(\"HTO_classification.global\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbb668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4989f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"HTO_classification.global\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4288f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4fd5c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test[\"HTO_classification.global\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca6beb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "7        1\n",
       "11       1\n",
       "16       1\n",
       "18       0\n",
       "        ..\n",
       "17305    1\n",
       "17306    0\n",
       "17311    1\n",
       "17317    1\n",
       "17320    0\n",
       "Name: HTO_classification.global, Length: 4122, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3d622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c91dd61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HTO4         1672\n",
       "HTO2_HTO4     932\n",
       "HTO1_HTO4     871\n",
       "HTO4_HTO5     568\n",
       "HTO3_HTO4      79\n",
       "Name: HTO_classification, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.HTO_classification.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a807bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe7f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3ee58dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\", axis = \"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a1cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ba97252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"HTO_classification\", axis = \"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1f30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ea630800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Doublet', 'Singlet'], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"HTO_classification.global\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a4b4e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"HTO_classification.global\"].replace({\"Doublet\" : 1, \"Singlet\":0}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1eab73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20cda47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"HTO_classification.global\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7721cbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TotalRNA</th>\n",
       "      <th>DetectedGenes</th>\n",
       "      <th>ExpressionCV</th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "      <th>PC_5</th>\n",
       "      <th>PC_6</th>\n",
       "      <th>...</th>\n",
       "      <th>PC_20</th>\n",
       "      <th>UMAP_1</th>\n",
       "      <th>UMAP_2</th>\n",
       "      <th>entropy</th>\n",
       "      <th>MitochondrialExpression</th>\n",
       "      <th>HTO_classification</th>\n",
       "      <th>percent.mito</th>\n",
       "      <th>mito.ribo_ratio</th>\n",
       "      <th>S.Score</th>\n",
       "      <th>G2M.Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCTGAGAACAACT</td>\n",
       "      <td>1368</td>\n",
       "      <td>809</td>\n",
       "      <td>12.921580</td>\n",
       "      <td>339.063207</td>\n",
       "      <td>79.917857</td>\n",
       "      <td>17.981489</td>\n",
       "      <td>-39.274429</td>\n",
       "      <td>53.414980</td>\n",
       "      <td>-16.621342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.698543</td>\n",
       "      <td>8.057654</td>\n",
       "      <td>-3.369327</td>\n",
       "      <td>6.229855</td>\n",
       "      <td>173</td>\n",
       "      <td>HTO2_HTO4</td>\n",
       "      <td>0.126462</td>\n",
       "      <td>0.473973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCTGAGACGCAAC</td>\n",
       "      <td>1481</td>\n",
       "      <td>745</td>\n",
       "      <td>13.116174</td>\n",
       "      <td>395.611183</td>\n",
       "      <td>7.899209</td>\n",
       "      <td>-47.137628</td>\n",
       "      <td>26.971731</td>\n",
       "      <td>-1.669082</td>\n",
       "      <td>8.549641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272925</td>\n",
       "      <td>4.610576</td>\n",
       "      <td>2.226939</td>\n",
       "      <td>6.056956</td>\n",
       "      <td>84</td>\n",
       "      <td>HTO2_HTO5</td>\n",
       "      <td>0.056718</td>\n",
       "      <td>0.139767</td>\n",
       "      <td>-0.227553</td>\n",
       "      <td>-0.227553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCTGAGATCCCGC</td>\n",
       "      <td>2183</td>\n",
       "      <td>1086</td>\n",
       "      <td>11.089327</td>\n",
       "      <td>351.875182</td>\n",
       "      <td>189.980935</td>\n",
       "      <td>43.534348</td>\n",
       "      <td>-51.459949</td>\n",
       "      <td>150.183664</td>\n",
       "      <td>-27.792936</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.909508</td>\n",
       "      <td>5.216998</td>\n",
       "      <td>-5.372590</td>\n",
       "      <td>6.460458</td>\n",
       "      <td>134</td>\n",
       "      <td>HTO5</td>\n",
       "      <td>0.061383</td>\n",
       "      <td>0.235501</td>\n",
       "      <td>-0.382076</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCTGAGCGATCCC</td>\n",
       "      <td>1739</td>\n",
       "      <td>749</td>\n",
       "      <td>13.132140</td>\n",
       "      <td>351.103107</td>\n",
       "      <td>5.655721</td>\n",
       "      <td>-36.473538</td>\n",
       "      <td>27.065455</td>\n",
       "      <td>-46.514153</td>\n",
       "      <td>22.601072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.790108</td>\n",
       "      <td>5.764953</td>\n",
       "      <td>5.673031</td>\n",
       "      <td>5.995373</td>\n",
       "      <td>52</td>\n",
       "      <td>HTO2</td>\n",
       "      <td>0.029902</td>\n",
       "      <td>0.067183</td>\n",
       "      <td>0.636535</td>\n",
       "      <td>0.424357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCTGAGCTGAAAT</td>\n",
       "      <td>4139</td>\n",
       "      <td>1642</td>\n",
       "      <td>10.909867</td>\n",
       "      <td>-790.648573</td>\n",
       "      <td>3.597314</td>\n",
       "      <td>10.548595</td>\n",
       "      <td>36.171136</td>\n",
       "      <td>-12.860454</td>\n",
       "      <td>24.219495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537122</td>\n",
       "      <td>-8.777119</td>\n",
       "      <td>1.941277</td>\n",
       "      <td>6.599805</td>\n",
       "      <td>151</td>\n",
       "      <td>HTO1_HTO2</td>\n",
       "      <td>0.036482</td>\n",
       "      <td>0.114829</td>\n",
       "      <td>-0.409494</td>\n",
       "      <td>-0.370941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  TotalRNA  DetectedGenes  ExpressionCV        PC_1  \\\n",
       "0  AAACCTGAGAACAACT      1368            809     12.921580  339.063207   \n",
       "1  AAACCTGAGACGCAAC      1481            745     13.116174  395.611183   \n",
       "2  AAACCTGAGATCCCGC      2183           1086     11.089327  351.875182   \n",
       "3  AAACCTGAGCGATCCC      1739            749     13.132140  351.103107   \n",
       "4  AAACCTGAGCTGAAAT      4139           1642     10.909867 -790.648573   \n",
       "\n",
       "         PC_2       PC_3       PC_4        PC_5       PC_6  ...     PC_20  \\\n",
       "0   79.917857  17.981489 -39.274429   53.414980 -16.621342  ... -0.698543   \n",
       "1    7.899209 -47.137628  26.971731   -1.669082   8.549641  ...  0.272925   \n",
       "2  189.980935  43.534348 -51.459949  150.183664 -27.792936  ... -1.909508   \n",
       "3    5.655721 -36.473538  27.065455  -46.514153  22.601072  ... -0.790108   \n",
       "4    3.597314  10.548595  36.171136  -12.860454  24.219495  ...  1.537122   \n",
       "\n",
       "     UMAP_1    UMAP_2   entropy  MitochondrialExpression  HTO_classification  \\\n",
       "0  8.057654 -3.369327  6.229855                      173           HTO2_HTO4   \n",
       "1  4.610576  2.226939  6.056956                       84           HTO2_HTO5   \n",
       "2  5.216998 -5.372590  6.460458                      134                HTO5   \n",
       "3  5.764953  5.673031  5.995373                       52                HTO2   \n",
       "4 -8.777119  1.941277  6.599805                      151           HTO1_HTO2   \n",
       "\n",
       "   percent.mito  mito.ribo_ratio   S.Score  G2M.Score  \n",
       "0      0.126462         0.473973  0.000000   0.000000  \n",
       "1      0.056718         0.139767 -0.227553  -0.227553  \n",
       "2      0.061383         0.235501 -0.382076   0.000000  \n",
       "3      0.029902         0.067183  0.636535   0.424357  \n",
       "4      0.036482         0.114829 -0.409494  -0.370941  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d2ccce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"HTO_classification.global\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f40dab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Doublet\n",
       "1    Doublet\n",
       "2    Singlet\n",
       "3    Singlet\n",
       "4    Doublet\n",
       "Name: HTO_classification.global, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ad31ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9474f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ca8e39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "413/413 [==============================] - 0s 475us/step - loss: 27.0358 - accuracy: 0.6343\n",
      "Epoch 2/100\n",
      "413/413 [==============================] - 0s 449us/step - loss: 1.9400 - accuracy: 0.6783\n",
      "Epoch 3/100\n",
      "413/413 [==============================] - 0s 489us/step - loss: 1.1943 - accuracy: 0.6751\n",
      "Epoch 4/100\n",
      "413/413 [==============================] - 0s 449us/step - loss: 0.9568 - accuracy: 0.6876\n",
      "Epoch 5/100\n",
      "413/413 [==============================] - 0s 463us/step - loss: 0.9054 - accuracy: 0.6989\n",
      "Epoch 6/100\n",
      "413/413 [==============================] - 0s 432us/step - loss: 0.8295 - accuracy: 0.7009\n",
      "Epoch 7/100\n",
      "413/413 [==============================] - 0s 458us/step - loss: 0.8037 - accuracy: 0.7070\n",
      "Epoch 8/100\n",
      "413/413 [==============================] - 0s 427us/step - loss: 0.8044 - accuracy: 0.7164\n",
      "Epoch 9/100\n",
      "413/413 [==============================] - 0s 435us/step - loss: 0.8219 - accuracy: 0.7051\n",
      "Epoch 10/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.7580 - accuracy: 0.7155\n",
      "Epoch 11/100\n",
      "413/413 [==============================] - 0s 435us/step - loss: 0.8697 - accuracy: 0.7064\n",
      "Epoch 12/100\n",
      "413/413 [==============================] - 0s 433us/step - loss: 0.8362 - accuracy: 0.7102\n",
      "Epoch 13/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.8923 - accuracy: 0.7095\n",
      "Epoch 14/100\n",
      "413/413 [==============================] - 0s 436us/step - loss: 0.7241 - accuracy: 0.7170\n",
      "Epoch 15/100\n",
      "413/413 [==============================] - 0s 434us/step - loss: 0.7936 - accuracy: 0.7117\n",
      "Epoch 16/100\n",
      "413/413 [==============================] - 0s 441us/step - loss: 0.8412 - accuracy: 0.7055\n",
      "Epoch 17/100\n",
      "413/413 [==============================] - 0s 436us/step - loss: 0.7260 - accuracy: 0.7170\n",
      "Epoch 18/100\n",
      "413/413 [==============================] - 0s 434us/step - loss: 0.6637 - accuracy: 0.7283\n",
      "Epoch 19/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.7939 - accuracy: 0.7015\n",
      "Epoch 20/100\n",
      "413/413 [==============================] - 0s 431us/step - loss: 0.7593 - accuracy: 0.7140\n",
      "Epoch 21/100\n",
      "413/413 [==============================] - 0s 432us/step - loss: 0.7943 - accuracy: 0.7130\n",
      "Epoch 22/100\n",
      "413/413 [==============================] - 0s 437us/step - loss: 0.7677 - accuracy: 0.7120\n",
      "Epoch 23/100\n",
      "413/413 [==============================] - 0s 437us/step - loss: 0.8821 - accuracy: 0.7048\n",
      "Epoch 24/100\n",
      "413/413 [==============================] - 0s 435us/step - loss: 0.8483 - accuracy: 0.7076\n",
      "Epoch 25/100\n",
      "413/413 [==============================] - 0s 446us/step - loss: 0.8546 - accuracy: 0.7048\n",
      "Epoch 26/100\n",
      "413/413 [==============================] - 0s 439us/step - loss: 0.7700 - accuracy: 0.7142\n",
      "Epoch 27/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.8232 - accuracy: 0.7129\n",
      "Epoch 28/100\n",
      "413/413 [==============================] - 0s 439us/step - loss: 0.7523 - accuracy: 0.7120\n",
      "Epoch 29/100\n",
      "413/413 [==============================] - 0s 436us/step - loss: 0.7271 - accuracy: 0.7210\n",
      "Epoch 30/100\n",
      "413/413 [==============================] - 0s 448us/step - loss: 0.8996 - accuracy: 0.7033\n",
      "Epoch 31/100\n",
      "413/413 [==============================] - 0s 432us/step - loss: 0.7762 - accuracy: 0.7235\n",
      "Epoch 32/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.7502 - accuracy: 0.7113\n",
      "Epoch 33/100\n",
      "413/413 [==============================] - 0s 434us/step - loss: 0.7386 - accuracy: 0.7163\n",
      "Epoch 34/100\n",
      "413/413 [==============================] - 0s 440us/step - loss: 0.7373 - accuracy: 0.7207\n",
      "Epoch 35/100\n",
      "413/413 [==============================] - 0s 439us/step - loss: 0.9122 - accuracy: 0.7047\n",
      "Epoch 36/100\n",
      "413/413 [==============================] - 0s 443us/step - loss: 0.8423 - accuracy: 0.7107\n",
      "Epoch 37/100\n",
      "413/413 [==============================] - 0s 437us/step - loss: 0.7397 - accuracy: 0.7196\n",
      "Epoch 38/100\n",
      "413/413 [==============================] - 0s 476us/step - loss: 0.7748 - accuracy: 0.7193\n",
      "Epoch 39/100\n",
      "413/413 [==============================] - 0s 443us/step - loss: 0.7023 - accuracy: 0.7207\n",
      "Epoch 40/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.7775 - accuracy: 0.7083\n",
      "Epoch 41/100\n",
      "413/413 [==============================] - 0s 434us/step - loss: 0.7832 - accuracy: 0.7123\n",
      "Epoch 42/100\n",
      "413/413 [==============================] - 0s 437us/step - loss: 0.7495 - accuracy: 0.7135\n",
      "Epoch 43/100\n",
      "413/413 [==============================] - 0s 437us/step - loss: 0.6961 - accuracy: 0.7186\n",
      "Epoch 44/100\n",
      "413/413 [==============================] - 0s 432us/step - loss: 0.7329 - accuracy: 0.7164\n",
      "Epoch 45/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.7603 - accuracy: 0.7098\n",
      "Epoch 46/100\n",
      "413/413 [==============================] - 0s 435us/step - loss: 0.7640 - accuracy: 0.7167\n",
      "Epoch 47/100\n",
      "413/413 [==============================] - 0s 435us/step - loss: 0.7406 - accuracy: 0.7161\n",
      "Epoch 48/100\n",
      "413/413 [==============================] - 0s 434us/step - loss: 0.7815 - accuracy: 0.7086\n",
      "Epoch 49/100\n",
      "413/413 [==============================] - 0s 433us/step - loss: 0.8288 - accuracy: 0.7102\n",
      "Epoch 50/100\n",
      "413/413 [==============================] - 0s 439us/step - loss: 0.8464 - accuracy: 0.7047\n",
      "Epoch 51/100\n",
      "413/413 [==============================] - 0s 432us/step - loss: 0.7729 - accuracy: 0.7117\n",
      "Epoch 52/100\n",
      "413/413 [==============================] - 0s 436us/step - loss: 0.7820 - accuracy: 0.7139\n",
      "Epoch 53/100\n",
      "413/413 [==============================] - 0s 440us/step - loss: 0.7054 - accuracy: 0.7204\n",
      "Epoch 54/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.7567 - accuracy: 0.7178\n",
      "Epoch 55/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.8308 - accuracy: 0.7089\n",
      "Epoch 56/100\n",
      "413/413 [==============================] - 0s 433us/step - loss: 0.7208 - accuracy: 0.7221\n",
      "Epoch 57/100\n",
      "413/413 [==============================] - 0s 434us/step - loss: 0.8073 - accuracy: 0.7080\n",
      "Epoch 58/100\n",
      "413/413 [==============================] - 0s 439us/step - loss: 0.8099 - accuracy: 0.7093\n",
      "Epoch 59/100\n",
      "413/413 [==============================] - 0s 429us/step - loss: 0.8657 - accuracy: 0.7033\n",
      "Epoch 60/100\n",
      "413/413 [==============================] - 0s 429us/step - loss: 0.7774 - accuracy: 0.7123\n",
      "Epoch 61/100\n",
      "413/413 [==============================] - 0s 436us/step - loss: 0.7385 - accuracy: 0.7170\n",
      "Epoch 62/100\n",
      "413/413 [==============================] - 0s 433us/step - loss: 0.7815 - accuracy: 0.7095\n",
      "Epoch 63/100\n",
      "413/413 [==============================] - 0s 446us/step - loss: 0.7527 - accuracy: 0.7181\n",
      "Epoch 64/100\n",
      "413/413 [==============================] - 0s 438us/step - loss: 0.6894 - accuracy: 0.7266\n",
      "Epoch 65/100\n",
      "413/413 [==============================] - 0s 433us/step - loss: 0.7772 - accuracy: 0.7137\n",
      "Epoch 66/100\n",
      "413/413 [==============================] - 0s 430us/step - loss: 0.8619 - accuracy: 0.7027\n",
      "Epoch 67/100\n",
      "413/413 [==============================] - 0s 443us/step - loss: 0.7398 - accuracy: 0.7207\n",
      "Epoch 68/100\n",
      "413/413 [==============================] - 0s 461us/step - loss: 0.7876 - accuracy: 0.7158\n",
      "Epoch 69/100\n",
      "413/413 [==============================] - 0s 392us/step - loss: 0.6986 - accuracy: 0.7204\n",
      "Epoch 70/100\n",
      "413/413 [==============================] - 0s 376us/step - loss: 0.7117 - accuracy: 0.7202\n",
      "Epoch 71/100\n",
      "413/413 [==============================] - 0s 375us/step - loss: 0.7662 - accuracy: 0.7124\n",
      "Epoch 72/100\n",
      "413/413 [==============================] - 0s 457us/step - loss: 0.7459 - accuracy: 0.7203\n",
      "Epoch 73/100\n",
      "413/413 [==============================] - 0s 479us/step - loss: 0.7851 - accuracy: 0.7106\n",
      "Epoch 74/100\n",
      "413/413 [==============================] - 0s 514us/step - loss: 0.7918 - accuracy: 0.7164\n",
      "Epoch 75/100\n",
      "413/413 [==============================] - 0s 514us/step - loss: 0.7596 - accuracy: 0.7175\n",
      "Epoch 76/100\n",
      "413/413 [==============================] - 0s 450us/step - loss: 0.7178 - accuracy: 0.7255\n",
      "Epoch 77/100\n",
      "413/413 [==============================] - 0s 441us/step - loss: 0.8626 - accuracy: 0.7089\n",
      "Epoch 78/100\n",
      "413/413 [==============================] - 0s 437us/step - loss: 0.8044 - accuracy: 0.7102\n",
      "Epoch 79/100\n",
      "413/413 [==============================] - 0s 437us/step - loss: 0.6943 - accuracy: 0.7252\n",
      "Epoch 80/100\n",
      "413/413 [==============================] - 0s 492us/step - loss: 0.7674 - accuracy: 0.7133\n",
      "Epoch 81/100\n",
      "413/413 [==============================] - 0s 430us/step - loss: 0.7755 - accuracy: 0.7173\n",
      "Epoch 82/100\n",
      "413/413 [==============================] - 0s 430us/step - loss: 0.7100 - accuracy: 0.7223\n",
      "Epoch 83/100\n",
      "413/413 [==============================] - 0s 432us/step - loss: 0.7065 - accuracy: 0.7234\n",
      "Epoch 84/100\n",
      "413/413 [==============================] - 0s 427us/step - loss: 0.7168 - accuracy: 0.7198\n",
      "Epoch 85/100\n",
      "413/413 [==============================] - 0s 436us/step - loss: 0.7533 - accuracy: 0.7142\n",
      "Epoch 86/100\n",
      "413/413 [==============================] - 0s 433us/step - loss: 0.6966 - accuracy: 0.7230\n",
      "Epoch 87/100\n",
      "413/413 [==============================] - 0s 434us/step - loss: 0.7059 - accuracy: 0.7236\n",
      "Epoch 88/100\n",
      "413/413 [==============================] - 0s 430us/step - loss: 0.8563 - accuracy: 0.7039\n",
      "Epoch 89/100\n",
      "413/413 [==============================] - 0s 432us/step - loss: 0.7777 - accuracy: 0.7125\n",
      "Epoch 90/100\n",
      "413/413 [==============================] - 0s 426us/step - loss: 0.7424 - accuracy: 0.7139\n",
      "Epoch 91/100\n",
      "413/413 [==============================] - 0s 431us/step - loss: 0.7569 - accuracy: 0.7189\n",
      "Epoch 92/100\n",
      "413/413 [==============================] - 0s 430us/step - loss: 0.7211 - accuracy: 0.7240\n",
      "Epoch 93/100\n",
      "413/413 [==============================] - 0s 437us/step - loss: 0.7099 - accuracy: 0.7195\n",
      "Epoch 94/100\n",
      "413/413 [==============================] - 0s 430us/step - loss: 0.7137 - accuracy: 0.7202\n",
      "Epoch 95/100\n",
      "413/413 [==============================] - 0s 430us/step - loss: 0.7879 - accuracy: 0.7116\n",
      "Epoch 96/100\n",
      "413/413 [==============================] - 0s 430us/step - loss: 0.6838 - accuracy: 0.7233\n",
      "Epoch 97/100\n",
      "413/413 [==============================] - 0s 432us/step - loss: 0.7694 - accuracy: 0.7132\n",
      "Epoch 98/100\n",
      "413/413 [==============================] - 0s 427us/step - loss: 0.7665 - accuracy: 0.7146\n",
      "Epoch 99/100\n",
      "413/413 [==============================] - 0s 430us/step - loss: 0.8024 - accuracy: 0.7122\n",
      "Epoch 100/100\n",
      "413/413 [==============================] - 0s 434us/step - loss: 0.7751 - accuracy: 0.7205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x295e87760>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(15, activation= \"relu\"),\n",
    "    keras.layers.Dense(1,  activation= \"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer = \"adam\",\n",
    "             loss = \"binary_crossentropy\",\n",
    "             metrics = [\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042b253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f8b23fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 403us/step - loss: 1.3686 - accuracy: 0.6647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3686212301254272, 0.6647258400917053]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f354c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909dc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec45877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 318us/step\n"
     ]
    }
   ],
   "source": [
    "yp = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e3425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "172223e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75541097],\n",
       "       [0.99694014],\n",
       "       [0.99473923],\n",
       "       [0.59440345],\n",
       "       [0.99949557]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa5d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "381429dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for element in yp:\n",
    "    if element >0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04779c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc610209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.28      0.40      1672\n",
      "           1       0.65      0.93      0.77      2450\n",
      "\n",
      "    accuracy                           0.66      4122\n",
      "   macro avg       0.69      0.60      0.59      4122\n",
      "weighted avg       0.68      0.66      0.62      4122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e954af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80e8c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(60, input_dim = 31, activation =\"relu\"),\n",
    "        keras.layers.Dense(30, activation =\"relu\"),\n",
    "        keras.layers.Dense(20, activation =\"relu\"),\n",
    "        keras.layers.Dense(1, activation =\"sigmoid\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer = \"adam\",\n",
    "                 loss = loss,\n",
    "                 metrics = [\"accuracy\"])\n",
    "\n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs = 300)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs = 300, class_weight = weights)\n",
    "\n",
    "    print(model.evaluate(X_test, y_test))\n",
    "\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    y_preds = np.round(y_preds)\n",
    "\n",
    "    print(\"Classification report: \\n\", classification_report(y_test, y_preds))\n",
    "\n",
    "    return y_preds\n",
    "\n",
    "#y_pred = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27feb73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dcf290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e8f897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "751c438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82      2781\n",
      "           1       0.67      0.30      0.41      1360\n",
      "\n",
      "    accuracy                           0.72      4141\n",
      "   macro avg       0.70      0.61      0.62      4141\n",
      "weighted avg       0.71      0.72      0.68      4141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "989a8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = df[~df['HTO_classification'].str.contains('HTO4')]\n",
    "df_train = df_train.drop(\"Unnamed: 0\", axis = \"columns\")\n",
    "df_train = df_train.drop(\"HTO_classification\", axis = \"columns\")\n",
    "#X_train = X_train.drop(\"HTO_classification.global\", axis = \"columns\")\n",
    "\n",
    "count_class_0, count_class_1 = df_train['HTO_classification.global'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "df_class_0 = df_train[df_train[\"HTO_classification.global\"] == 0]\n",
    "df_class_1 = df_train[df_train[\"HTO_classification.global\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e14669ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0, count_class_1 = df_train['HTO_classification.global'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bce887e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9644, 3556)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class_0 , count_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c93d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86a641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f16ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "127f109d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10668, 32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1.shape\n",
    "\n",
    "df_class_0_under = df_class_0.sample(count_class_1*2)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1],axis = 0)\n",
    "df_test_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d5b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "54b21e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7112\n",
       "1    3556\n",
       "Name: HTO_classification.global, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_under['HTO_classification.global'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f7cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "521b11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_test_under.drop(\"HTO_classification.global\", axis = \"columns\")\n",
    "y_train = df_test_under[\"HTO_classification.global\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de61f2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalRNA</th>\n",
       "      <th>DetectedGenes</th>\n",
       "      <th>ExpressionCV</th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "      <th>PC_5</th>\n",
       "      <th>PC_6</th>\n",
       "      <th>PC_7</th>\n",
       "      <th>...</th>\n",
       "      <th>PC_19</th>\n",
       "      <th>PC_20</th>\n",
       "      <th>UMAP_1</th>\n",
       "      <th>UMAP_2</th>\n",
       "      <th>entropy</th>\n",
       "      <th>MitochondrialExpression</th>\n",
       "      <th>percent.mito</th>\n",
       "      <th>mito.ribo_ratio</th>\n",
       "      <th>S.Score</th>\n",
       "      <th>G2M.Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10806</th>\n",
       "      <td>1308</td>\n",
       "      <td>776</td>\n",
       "      <td>10.306602</td>\n",
       "      <td>353.660019</td>\n",
       "      <td>132.119338</td>\n",
       "      <td>27.485805</td>\n",
       "      <td>-41.381757</td>\n",
       "      <td>63.790793</td>\n",
       "      <td>-24.892712</td>\n",
       "      <td>8.762283</td>\n",
       "      <td>...</td>\n",
       "      <td>3.593907</td>\n",
       "      <td>-3.106893</td>\n",
       "      <td>6.934060</td>\n",
       "      <td>-4.573126</td>\n",
       "      <td>6.323704</td>\n",
       "      <td>59</td>\n",
       "      <td>0.045107</td>\n",
       "      <td>0.183230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.239668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>1498</td>\n",
       "      <td>665</td>\n",
       "      <td>13.562240</td>\n",
       "      <td>416.861564</td>\n",
       "      <td>-36.467180</td>\n",
       "      <td>-56.659711</td>\n",
       "      <td>37.809639</td>\n",
       "      <td>-24.728414</td>\n",
       "      <td>10.786278</td>\n",
       "      <td>4.331727</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.217017</td>\n",
       "      <td>-0.735131</td>\n",
       "      <td>1.538690</td>\n",
       "      <td>4.768099</td>\n",
       "      <td>5.914349</td>\n",
       "      <td>45</td>\n",
       "      <td>0.030040</td>\n",
       "      <td>0.065407</td>\n",
       "      <td>-0.226449</td>\n",
       "      <td>-0.295981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>1434</td>\n",
       "      <td>698</td>\n",
       "      <td>12.781239</td>\n",
       "      <td>364.560211</td>\n",
       "      <td>73.480853</td>\n",
       "      <td>-8.810298</td>\n",
       "      <td>-24.882372</td>\n",
       "      <td>-1.091283</td>\n",
       "      <td>-1.364848</td>\n",
       "      <td>22.670626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>-1.595997</td>\n",
       "      <td>6.947287</td>\n",
       "      <td>-0.857919</td>\n",
       "      <td>6.032390</td>\n",
       "      <td>48</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>0.086486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.531182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>1962</td>\n",
       "      <td>1050</td>\n",
       "      <td>10.203219</td>\n",
       "      <td>-867.818349</td>\n",
       "      <td>-3.242531</td>\n",
       "      <td>-29.296966</td>\n",
       "      <td>-2.074049</td>\n",
       "      <td>-1.363190</td>\n",
       "      <td>-22.086732</td>\n",
       "      <td>9.642906</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482427</td>\n",
       "      <td>-3.305366</td>\n",
       "      <td>-8.794503</td>\n",
       "      <td>2.227866</td>\n",
       "      <td>6.495708</td>\n",
       "      <td>103</td>\n",
       "      <td>0.052497</td>\n",
       "      <td>0.217759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12335</th>\n",
       "      <td>2208</td>\n",
       "      <td>1041</td>\n",
       "      <td>11.878790</td>\n",
       "      <td>390.396227</td>\n",
       "      <td>56.274706</td>\n",
       "      <td>-28.291594</td>\n",
       "      <td>-8.231742</td>\n",
       "      <td>6.789114</td>\n",
       "      <td>-12.727285</td>\n",
       "      <td>-12.872341</td>\n",
       "      <td>...</td>\n",
       "      <td>3.085431</td>\n",
       "      <td>-1.854989</td>\n",
       "      <td>7.506605</td>\n",
       "      <td>0.333737</td>\n",
       "      <td>6.318798</td>\n",
       "      <td>126</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.155748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.190000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TotalRNA  DetectedGenes  ExpressionCV        PC_1        PC_2  \\\n",
       "10806      1308            776     10.306602  353.660019  132.119338   \n",
       "1981       1498            665     13.562240  416.861564  -36.467180   \n",
       "10681      1434            698     12.781239  364.560211   73.480853   \n",
       "3654       1962           1050     10.203219 -867.818349   -3.242531   \n",
       "12335      2208           1041     11.878790  390.396227   56.274706   \n",
       "\n",
       "            PC_3       PC_4       PC_5       PC_6       PC_7  ...     PC_19  \\\n",
       "10806  27.485805 -41.381757  63.790793 -24.892712   8.762283  ...  3.593907   \n",
       "1981  -56.659711  37.809639 -24.728414  10.786278   4.331727  ... -2.217017   \n",
       "10681  -8.810298 -24.882372  -1.091283  -1.364848  22.670626  ...  0.004359   \n",
       "3654  -29.296966  -2.074049  -1.363190 -22.086732   9.642906  ...  1.482427   \n",
       "12335 -28.291594  -8.231742   6.789114 -12.727285 -12.872341  ...  3.085431   \n",
       "\n",
       "          PC_20    UMAP_1    UMAP_2   entropy  MitochondrialExpression  \\\n",
       "10806 -3.106893  6.934060 -4.573126  6.323704                       59   \n",
       "1981  -0.735131  1.538690  4.768099  5.914349                       45   \n",
       "10681 -1.595997  6.947287 -0.857919  6.032390                       48   \n",
       "3654  -3.305366 -8.794503  2.227866  6.495708                      103   \n",
       "12335 -1.854989  7.506605  0.333737  6.318798                      126   \n",
       "\n",
       "       percent.mito  mito.ribo_ratio   S.Score  G2M.Score  \n",
       "10806      0.045107         0.183230  0.000000  -0.239668  \n",
       "1981       0.030040         0.065407 -0.226449  -0.295981  \n",
       "10681      0.033473         0.086486  0.000000  -0.531182  \n",
       "3654       0.052497         0.217759  0.000000   0.091662  \n",
       "12335      0.057065         0.155748  0.000000  -0.190000  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1d0b0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['HTO_classification'].str.contains('HTO4')]\n",
    "X_test = df_test.drop(\"Unnamed: 0\", axis = \"columns\")\n",
    "X_test = X_test.drop(\"HTO_classification\", axis = \"columns\")\n",
    "X_test = X_test.drop(\"HTO_classification.global\", axis = \"columns\")\n",
    "y_test = df_test[\"HTO_classification.global\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e0737a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =15,stratify = y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0169e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on your training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d47c70b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39436067, 0.46008169, 0.05929574, ..., 0.06543571, 0.56221709,\n",
       "        0.28889179],\n",
       "       [0.02654728, 0.06164129, 0.03228911, ..., 0.13554255, 0.33487888,\n",
       "        0.16128103],\n",
       "       [0.04508325, 0.01448199, 0.07432895, ..., 0.08077736, 0.33487888,\n",
       "        0.22118945],\n",
       "       ...,\n",
       "       [0.08663211, 0.17044189, 0.02433433, ..., 0.23508051, 0.25154224,\n",
       "        0.17064382],\n",
       "       [0.08341188, 0.18678054, 0.02685788, ..., 0.16788973, 0.33487888,\n",
       "        0.31170693],\n",
       "       [0.09299403, 0.19346454, 0.02656789, ..., 0.16081401, 0.33487888,\n",
       "        0.19306835]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c419997e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb151fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d878deec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "603/603 [==============================] - 1s 552us/step - loss: 2.4472 - accuracy: 0.6076\n",
      "Epoch 2/300\n",
      "603/603 [==============================] - 0s 540us/step - loss: 0.8800 - accuracy: 0.6265\n",
      "Epoch 3/300\n",
      "603/603 [==============================] - 0s 612us/step - loss: 0.7423 - accuracy: 0.6520\n",
      "Epoch 4/300\n",
      "603/603 [==============================] - 0s 630us/step - loss: 0.7372 - accuracy: 0.6551\n",
      "Epoch 5/300\n",
      "603/603 [==============================] - 0s 558us/step - loss: 0.6987 - accuracy: 0.6616\n",
      "Epoch 6/300\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.6615 - accuracy: 0.6639\n",
      "Epoch 7/300\n",
      "603/603 [==============================] - 0s 582us/step - loss: 0.6407 - accuracy: 0.6719\n",
      "Epoch 8/300\n",
      "603/603 [==============================] - 0s 626us/step - loss: 0.6371 - accuracy: 0.6732\n",
      "Epoch 9/300\n",
      "603/603 [==============================] - 0s 653us/step - loss: 0.6159 - accuracy: 0.6808\n",
      "Epoch 10/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.6178 - accuracy: 0.6778\n",
      "Epoch 11/300\n",
      "603/603 [==============================] - 0s 579us/step - loss: 0.6070 - accuracy: 0.6851\n",
      "Epoch 12/300\n",
      "603/603 [==============================] - 0s 581us/step - loss: 0.6040 - accuracy: 0.6822\n",
      "Epoch 13/300\n",
      "603/603 [==============================] - 0s 623us/step - loss: 0.5951 - accuracy: 0.6856\n",
      "Epoch 14/300\n",
      "603/603 [==============================] - 0s 645us/step - loss: 0.5929 - accuracy: 0.6875\n",
      "Epoch 15/300\n",
      "603/603 [==============================] - 0s 581us/step - loss: 0.5857 - accuracy: 0.6955\n",
      "Epoch 16/300\n",
      "603/603 [==============================] - 0s 570us/step - loss: 0.5871 - accuracy: 0.6935\n",
      "Epoch 17/300\n",
      "603/603 [==============================] - 0s 571us/step - loss: 0.5930 - accuracy: 0.6888\n",
      "Epoch 18/300\n",
      "603/603 [==============================] - 0s 567us/step - loss: 0.5862 - accuracy: 0.6918\n",
      "Epoch 19/300\n",
      "603/603 [==============================] - 0s 569us/step - loss: 0.5845 - accuracy: 0.6950\n",
      "Epoch 20/300\n",
      "603/603 [==============================] - 0s 571us/step - loss: 0.5837 - accuracy: 0.6968\n",
      "Epoch 21/300\n",
      "603/603 [==============================] - 0s 574us/step - loss: 0.5871 - accuracy: 0.6961\n",
      "Epoch 22/300\n",
      "603/603 [==============================] - 0s 567us/step - loss: 0.5830 - accuracy: 0.6973\n",
      "Epoch 23/300\n",
      "603/603 [==============================] - 0s 569us/step - loss: 0.5815 - accuracy: 0.6953\n",
      "Epoch 24/300\n",
      "603/603 [==============================] - 0s 568us/step - loss: 0.5828 - accuracy: 0.6936\n",
      "Epoch 25/300\n",
      "603/603 [==============================] - 0s 573us/step - loss: 0.5807 - accuracy: 0.6964\n",
      "Epoch 26/300\n",
      "603/603 [==============================] - 0s 569us/step - loss: 0.5776 - accuracy: 0.7002\n",
      "Epoch 27/300\n",
      "603/603 [==============================] - 0s 572us/step - loss: 0.5778 - accuracy: 0.7000\n",
      "Epoch 28/300\n",
      "603/603 [==============================] - 0s 569us/step - loss: 0.5773 - accuracy: 0.7005\n",
      "Epoch 29/300\n",
      "603/603 [==============================] - 0s 573us/step - loss: 0.5795 - accuracy: 0.6979\n",
      "Epoch 30/300\n",
      "603/603 [==============================] - 0s 579us/step - loss: 0.5752 - accuracy: 0.7005\n",
      "Epoch 31/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.5780 - accuracy: 0.6991\n",
      "Epoch 32/300\n",
      "603/603 [==============================] - 0s 591us/step - loss: 0.5759 - accuracy: 0.6991\n",
      "Epoch 33/300\n",
      "603/603 [==============================] - 0s 629us/step - loss: 0.5746 - accuracy: 0.6995\n",
      "Epoch 34/300\n",
      "603/603 [==============================] - 0s 639us/step - loss: 0.5736 - accuracy: 0.7006\n",
      "Epoch 35/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.5740 - accuracy: 0.7004\n",
      "Epoch 36/300\n",
      "603/603 [==============================] - 0s 648us/step - loss: 0.5739 - accuracy: 0.7007\n",
      "Epoch 37/300\n",
      "603/603 [==============================] - 0s 614us/step - loss: 0.5735 - accuracy: 0.7008\n",
      "Epoch 38/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.5713 - accuracy: 0.7047\n",
      "Epoch 39/300\n",
      "603/603 [==============================] - 0s 641us/step - loss: 0.5702 - accuracy: 0.7015\n",
      "Epoch 40/300\n",
      "603/603 [==============================] - 0s 618us/step - loss: 0.5711 - accuracy: 0.7013\n",
      "Epoch 41/300\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.5690 - accuracy: 0.7044\n",
      "Epoch 42/300\n",
      "603/603 [==============================] - 0s 619us/step - loss: 0.5701 - accuracy: 0.7021\n",
      "Epoch 43/300\n",
      "603/603 [==============================] - 0s 613us/step - loss: 0.5678 - accuracy: 0.7034\n",
      "Epoch 44/300\n",
      "603/603 [==============================] - 0s 686us/step - loss: 0.5678 - accuracy: 0.7054\n",
      "Epoch 45/300\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.5660 - accuracy: 0.7034\n",
      "Epoch 46/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.5653 - accuracy: 0.7066\n",
      "Epoch 47/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.5660 - accuracy: 0.7044\n",
      "Epoch 48/300\n",
      "603/603 [==============================] - 0s 678us/step - loss: 0.5666 - accuracy: 0.7085\n",
      "Epoch 49/300\n",
      "603/603 [==============================] - 0s 611us/step - loss: 0.5654 - accuracy: 0.7062\n",
      "Epoch 50/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.5647 - accuracy: 0.7046\n",
      "Epoch 51/300\n",
      "603/603 [==============================] - 0s 585us/step - loss: 0.5647 - accuracy: 0.7076\n",
      "Epoch 52/300\n",
      "603/603 [==============================] - 0s 625us/step - loss: 0.5645 - accuracy: 0.7070\n",
      "Epoch 53/300\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.5615 - accuracy: 0.7100\n",
      "Epoch 54/300\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.5608 - accuracy: 0.7093\n",
      "Epoch 55/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.5616 - accuracy: 0.7121\n",
      "Epoch 56/300\n",
      "603/603 [==============================] - 0s 613us/step - loss: 0.5623 - accuracy: 0.7080\n",
      "Epoch 57/300\n",
      "603/603 [==============================] - 0s 652us/step - loss: 0.5605 - accuracy: 0.7120\n",
      "Epoch 58/300\n",
      "603/603 [==============================] - 0s 641us/step - loss: 0.5607 - accuracy: 0.7099\n",
      "Epoch 59/300\n",
      "603/603 [==============================] - 0s 623us/step - loss: 0.5585 - accuracy: 0.7127\n",
      "Epoch 60/300\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.5586 - accuracy: 0.7116\n",
      "Epoch 61/300\n",
      "603/603 [==============================] - 0s 634us/step - loss: 0.5609 - accuracy: 0.7086\n",
      "Epoch 62/300\n",
      "603/603 [==============================] - 0s 621us/step - loss: 0.5586 - accuracy: 0.7091\n",
      "Epoch 63/300\n",
      "603/603 [==============================] - 0s 633us/step - loss: 0.5561 - accuracy: 0.7116\n",
      "Epoch 64/300\n",
      "603/603 [==============================] - 0s 593us/step - loss: 0.5573 - accuracy: 0.7116\n",
      "Epoch 65/300\n",
      "603/603 [==============================] - 0s 596us/step - loss: 0.5573 - accuracy: 0.7136\n",
      "Epoch 66/300\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.5574 - accuracy: 0.7121\n",
      "Epoch 67/300\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.5551 - accuracy: 0.7141\n",
      "Epoch 68/300\n",
      "603/603 [==============================] - 0s 616us/step - loss: 0.5550 - accuracy: 0.7158\n",
      "Epoch 69/300\n",
      "603/603 [==============================] - 0s 618us/step - loss: 0.5549 - accuracy: 0.7136\n",
      "Epoch 70/300\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.5528 - accuracy: 0.7143\n",
      "Epoch 71/300\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.5533 - accuracy: 0.7153\n",
      "Epoch 72/300\n",
      "603/603 [==============================] - 0s 623us/step - loss: 0.5531 - accuracy: 0.7139\n",
      "Epoch 73/300\n",
      "603/603 [==============================] - 0s 590us/step - loss: 0.5514 - accuracy: 0.7166\n",
      "Epoch 74/300\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.5529 - accuracy: 0.7146\n",
      "Epoch 75/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.5508 - accuracy: 0.7147\n",
      "Epoch 76/300\n",
      "603/603 [==============================] - 0s 588us/step - loss: 0.5500 - accuracy: 0.7174\n",
      "Epoch 77/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.5501 - accuracy: 0.7155\n",
      "Epoch 78/300\n",
      "603/603 [==============================] - 0s 587us/step - loss: 0.5487 - accuracy: 0.7179\n",
      "Epoch 79/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.5502 - accuracy: 0.7126\n",
      "Epoch 80/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.5520 - accuracy: 0.7163\n",
      "Epoch 81/300\n",
      "603/603 [==============================] - 0s 603us/step - loss: 0.5478 - accuracy: 0.7142\n",
      "Epoch 82/300\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.5478 - accuracy: 0.7189\n",
      "Epoch 83/300\n",
      "603/603 [==============================] - 0s 598us/step - loss: 0.5452 - accuracy: 0.7193\n",
      "Epoch 84/300\n",
      "603/603 [==============================] - 0s 578us/step - loss: 0.5453 - accuracy: 0.7192\n",
      "Epoch 85/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.5463 - accuracy: 0.7209\n",
      "Epoch 86/300\n",
      "603/603 [==============================] - 0s 607us/step - loss: 0.5436 - accuracy: 0.7210\n",
      "Epoch 87/300\n",
      "603/603 [==============================] - 0s 681us/step - loss: 0.5442 - accuracy: 0.7207\n",
      "Epoch 88/300\n",
      "603/603 [==============================] - 0s 614us/step - loss: 0.5420 - accuracy: 0.7198\n",
      "Epoch 89/300\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.5434 - accuracy: 0.7206\n",
      "Epoch 90/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5419 - accuracy: 0.7214\n",
      "Epoch 91/300\n",
      "603/603 [==============================] - 0s 652us/step - loss: 0.5434 - accuracy: 0.7218\n",
      "Epoch 92/300\n",
      "603/603 [==============================] - 0s 636us/step - loss: 0.5411 - accuracy: 0.7198\n",
      "Epoch 93/300\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.5451 - accuracy: 0.7179\n",
      "Epoch 94/300\n",
      "603/603 [==============================] - 0s 586us/step - loss: 0.5426 - accuracy: 0.7201\n",
      "Epoch 95/300\n",
      "603/603 [==============================] - 0s 589us/step - loss: 0.5414 - accuracy: 0.7215\n",
      "Epoch 96/300\n",
      "603/603 [==============================] - 0s 607us/step - loss: 0.5422 - accuracy: 0.7195\n",
      "Epoch 97/300\n",
      "603/603 [==============================] - 0s 625us/step - loss: 0.5396 - accuracy: 0.7218\n",
      "Epoch 98/300\n",
      "603/603 [==============================] - 0s 626us/step - loss: 0.5406 - accuracy: 0.7212\n",
      "Epoch 99/300\n",
      "603/603 [==============================] - 0s 588us/step - loss: 0.5381 - accuracy: 0.7224\n",
      "Epoch 100/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5412 - accuracy: 0.7188\n",
      "Epoch 101/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.5377 - accuracy: 0.7209\n",
      "Epoch 102/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.5385 - accuracy: 0.7208\n",
      "Epoch 103/300\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.5382 - accuracy: 0.7204\n",
      "Epoch 104/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.5393 - accuracy: 0.7208\n",
      "Epoch 105/300\n",
      "603/603 [==============================] - 0s 600us/step - loss: 0.5356 - accuracy: 0.7234\n",
      "Epoch 106/300\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.5355 - accuracy: 0.7249\n",
      "Epoch 107/300\n",
      "603/603 [==============================] - 0s 605us/step - loss: 0.5377 - accuracy: 0.7209\n",
      "Epoch 108/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.5373 - accuracy: 0.7228\n",
      "Epoch 109/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.5353 - accuracy: 0.7240\n",
      "Epoch 110/300\n",
      "603/603 [==============================] - 0s 586us/step - loss: 0.5350 - accuracy: 0.7238\n",
      "Epoch 111/300\n",
      "603/603 [==============================] - 0s 598us/step - loss: 0.5389 - accuracy: 0.7207\n",
      "Epoch 112/300\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.5373 - accuracy: 0.7238\n",
      "Epoch 113/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5327 - accuracy: 0.7231\n",
      "Epoch 114/300\n",
      "603/603 [==============================] - 0s 588us/step - loss: 0.5358 - accuracy: 0.7215\n",
      "Epoch 115/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.5346 - accuracy: 0.7255\n",
      "Epoch 116/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5341 - accuracy: 0.7249\n",
      "Epoch 117/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5336 - accuracy: 0.7211\n",
      "Epoch 118/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.5363 - accuracy: 0.7230\n",
      "Epoch 119/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.5348 - accuracy: 0.7237\n",
      "Epoch 120/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.5334 - accuracy: 0.7221\n",
      "Epoch 121/300\n",
      "603/603 [==============================] - 0s 624us/step - loss: 0.5332 - accuracy: 0.7241\n",
      "Epoch 122/300\n",
      "603/603 [==============================] - 0s 596us/step - loss: 0.5343 - accuracy: 0.7263\n",
      "Epoch 123/300\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.5316 - accuracy: 0.7284\n",
      "Epoch 124/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.5312 - accuracy: 0.7241\n",
      "Epoch 125/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.5320 - accuracy: 0.7253\n",
      "Epoch 126/300\n",
      "603/603 [==============================] - 0s 587us/step - loss: 0.5292 - accuracy: 0.7271\n",
      "Epoch 127/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.5325 - accuracy: 0.7239\n",
      "Epoch 128/300\n",
      "603/603 [==============================] - 0s 603us/step - loss: 0.5298 - accuracy: 0.7274\n",
      "Epoch 129/300\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.5302 - accuracy: 0.7254\n",
      "Epoch 130/300\n",
      "603/603 [==============================] - 0s 619us/step - loss: 0.5290 - accuracy: 0.7271\n",
      "Epoch 131/300\n",
      "603/603 [==============================] - 0s 667us/step - loss: 0.5274 - accuracy: 0.7280\n",
      "Epoch 132/300\n",
      "603/603 [==============================] - 0s 606us/step - loss: 0.5264 - accuracy: 0.7288\n",
      "Epoch 133/300\n",
      "603/603 [==============================] - 0s 606us/step - loss: 0.5265 - accuracy: 0.7274\n",
      "Epoch 134/300\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.5271 - accuracy: 0.7298\n",
      "Epoch 135/300\n",
      "603/603 [==============================] - 0s 654us/step - loss: 0.5279 - accuracy: 0.7287\n",
      "Epoch 136/300\n",
      "603/603 [==============================] - 0s 618us/step - loss: 0.5269 - accuracy: 0.7290\n",
      "Epoch 137/300\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.5244 - accuracy: 0.7276\n",
      "Epoch 138/300\n",
      "603/603 [==============================] - 0s 627us/step - loss: 0.5272 - accuracy: 0.7287\n",
      "Epoch 139/300\n",
      "603/603 [==============================] - 0s 643us/step - loss: 0.5241 - accuracy: 0.7292\n",
      "Epoch 140/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5251 - accuracy: 0.7298\n",
      "Epoch 141/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.5232 - accuracy: 0.7296\n",
      "Epoch 142/300\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.5265 - accuracy: 0.7293\n",
      "Epoch 143/300\n",
      "603/603 [==============================] - 0s 612us/step - loss: 0.5225 - accuracy: 0.7286\n",
      "Epoch 144/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.5246 - accuracy: 0.7301\n",
      "Epoch 145/300\n",
      "603/603 [==============================] - 0s 596us/step - loss: 0.5235 - accuracy: 0.7285\n",
      "Epoch 146/300\n",
      "603/603 [==============================] - 0s 598us/step - loss: 0.5228 - accuracy: 0.7290\n",
      "Epoch 147/300\n",
      "603/603 [==============================] - 0s 616us/step - loss: 0.5206 - accuracy: 0.7286\n",
      "Epoch 148/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5197 - accuracy: 0.7327\n",
      "Epoch 149/300\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.5201 - accuracy: 0.7307\n",
      "Epoch 150/300\n",
      "603/603 [==============================] - 0s 600us/step - loss: 0.5220 - accuracy: 0.7287\n",
      "Epoch 151/300\n",
      "603/603 [==============================] - 0s 600us/step - loss: 0.5194 - accuracy: 0.7318\n",
      "Epoch 152/300\n",
      "603/603 [==============================] - 0s 603us/step - loss: 0.5202 - accuracy: 0.7329\n",
      "Epoch 153/300\n",
      "603/603 [==============================] - 0s 638us/step - loss: 0.5198 - accuracy: 0.7320\n",
      "Epoch 154/300\n",
      "603/603 [==============================] - 0s 606us/step - loss: 0.5209 - accuracy: 0.7305\n",
      "Epoch 155/300\n",
      "603/603 [==============================] - 0s 589us/step - loss: 0.5171 - accuracy: 0.7322\n",
      "Epoch 156/300\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.5180 - accuracy: 0.7315\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 618us/step - loss: 0.5199 - accuracy: 0.7311\n",
      "Epoch 158/300\n",
      "603/603 [==============================] - 0s 607us/step - loss: 0.5199 - accuracy: 0.7304\n",
      "Epoch 159/300\n",
      "603/603 [==============================] - 0s 623us/step - loss: 0.5169 - accuracy: 0.7322\n",
      "Epoch 160/300\n",
      "603/603 [==============================] - 0s 612us/step - loss: 0.5186 - accuracy: 0.7300\n",
      "Epoch 161/300\n",
      "603/603 [==============================] - 0s 610us/step - loss: 0.5154 - accuracy: 0.7323\n",
      "Epoch 162/300\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.5164 - accuracy: 0.7351\n",
      "Epoch 163/300\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.5179 - accuracy: 0.7305\n",
      "Epoch 164/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.5129 - accuracy: 0.7343\n",
      "Epoch 165/300\n",
      "603/603 [==============================] - 0s 579us/step - loss: 0.5129 - accuracy: 0.7361\n",
      "Epoch 166/300\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.5180 - accuracy: 0.7312\n",
      "Epoch 167/300\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.5179 - accuracy: 0.7331\n",
      "Epoch 168/300\n",
      "603/603 [==============================] - 0s 587us/step - loss: 0.5149 - accuracy: 0.7310\n",
      "Epoch 169/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.5131 - accuracy: 0.7339\n",
      "Epoch 170/300\n",
      "603/603 [==============================] - 0s 593us/step - loss: 0.5140 - accuracy: 0.7339\n",
      "Epoch 171/300\n",
      "603/603 [==============================] - 0s 605us/step - loss: 0.5106 - accuracy: 0.7373\n",
      "Epoch 172/300\n",
      "603/603 [==============================] - 0s 596us/step - loss: 0.5131 - accuracy: 0.7336\n",
      "Epoch 173/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.5111 - accuracy: 0.7345\n",
      "Epoch 174/300\n",
      "603/603 [==============================] - 0s 669us/step - loss: 0.5123 - accuracy: 0.7353\n",
      "Epoch 175/300\n",
      "603/603 [==============================] - 0s 600us/step - loss: 0.5124 - accuracy: 0.7323\n",
      "Epoch 176/300\n",
      "603/603 [==============================] - 0s 587us/step - loss: 0.5141 - accuracy: 0.7335\n",
      "Epoch 177/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5107 - accuracy: 0.7377\n",
      "Epoch 178/300\n",
      "603/603 [==============================] - 0s 667us/step - loss: 0.5107 - accuracy: 0.7375\n",
      "Epoch 179/300\n",
      "603/603 [==============================] - 0s 659us/step - loss: 0.5121 - accuracy: 0.7361\n",
      "Epoch 180/300\n",
      "603/603 [==============================] - 0s 625us/step - loss: 0.5139 - accuracy: 0.7351\n",
      "Epoch 181/300\n",
      "603/603 [==============================] - 0s 641us/step - loss: 0.5096 - accuracy: 0.7368\n",
      "Epoch 182/300\n",
      "603/603 [==============================] - 0s 627us/step - loss: 0.5117 - accuracy: 0.7359\n",
      "Epoch 183/300\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.5090 - accuracy: 0.7384\n",
      "Epoch 184/300\n",
      "603/603 [==============================] - 0s 591us/step - loss: 0.5067 - accuracy: 0.7381\n",
      "Epoch 185/300\n",
      "603/603 [==============================] - 0s 606us/step - loss: 0.5097 - accuracy: 0.7374\n",
      "Epoch 186/300\n",
      "603/603 [==============================] - 0s 613us/step - loss: 0.5088 - accuracy: 0.7369\n",
      "Epoch 187/300\n",
      "603/603 [==============================] - 0s 606us/step - loss: 0.5073 - accuracy: 0.7361\n",
      "Epoch 188/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.5106 - accuracy: 0.7381\n",
      "Epoch 189/300\n",
      "603/603 [==============================] - 0s 610us/step - loss: 0.5052 - accuracy: 0.7376\n",
      "Epoch 190/300\n",
      "603/603 [==============================] - 0s 630us/step - loss: 0.5084 - accuracy: 0.7366\n",
      "Epoch 191/300\n",
      "603/603 [==============================] - 0s 618us/step - loss: 0.5051 - accuracy: 0.7403\n",
      "Epoch 192/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.5053 - accuracy: 0.7394\n",
      "Epoch 193/300\n",
      "603/603 [==============================] - 0s 598us/step - loss: 0.5060 - accuracy: 0.7403\n",
      "Epoch 194/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5053 - accuracy: 0.7375\n",
      "Epoch 195/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.5035 - accuracy: 0.7407\n",
      "Epoch 196/300\n",
      "603/603 [==============================] - 0s 591us/step - loss: 0.5036 - accuracy: 0.7392\n",
      "Epoch 197/300\n",
      "603/603 [==============================] - 0s 603us/step - loss: 0.5037 - accuracy: 0.7411\n",
      "Epoch 198/300\n",
      "603/603 [==============================] - 0s 619us/step - loss: 0.5041 - accuracy: 0.7405\n",
      "Epoch 199/300\n",
      "603/603 [==============================] - 0s 588us/step - loss: 0.5018 - accuracy: 0.7435\n",
      "Epoch 200/300\n",
      "603/603 [==============================] - 0s 607us/step - loss: 0.5034 - accuracy: 0.7398\n",
      "Epoch 201/300\n",
      "603/603 [==============================] - 0s 613us/step - loss: 0.5064 - accuracy: 0.7372\n",
      "Epoch 202/300\n",
      "603/603 [==============================] - 0s 627us/step - loss: 0.5041 - accuracy: 0.7392\n",
      "Epoch 203/300\n",
      "603/603 [==============================] - 0s 593us/step - loss: 0.5009 - accuracy: 0.7426\n",
      "Epoch 204/300\n",
      "603/603 [==============================] - 0s 610us/step - loss: 0.5014 - accuracy: 0.7423\n",
      "Epoch 205/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.5023 - accuracy: 0.7410\n",
      "Epoch 206/300\n",
      "603/603 [==============================] - 0s 605us/step - loss: 0.5028 - accuracy: 0.7410\n",
      "Epoch 207/300\n",
      "603/603 [==============================] - 0s 600us/step - loss: 0.5073 - accuracy: 0.7403\n",
      "Epoch 208/300\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.5055 - accuracy: 0.7420\n",
      "Epoch 209/300\n",
      "603/603 [==============================] - 0s 591us/step - loss: 0.5017 - accuracy: 0.7427\n",
      "Epoch 210/300\n",
      "603/603 [==============================] - 0s 598us/step - loss: 0.5027 - accuracy: 0.7407\n",
      "Epoch 211/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.5002 - accuracy: 0.7406\n",
      "Epoch 212/300\n",
      "603/603 [==============================] - 0s 606us/step - loss: 0.5031 - accuracy: 0.7405\n",
      "Epoch 213/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.5001 - accuracy: 0.7417\n",
      "Epoch 214/300\n",
      "603/603 [==============================] - 0s 608us/step - loss: 0.4969 - accuracy: 0.7420\n",
      "Epoch 215/300\n",
      "603/603 [==============================] - 0s 591us/step - loss: 0.4972 - accuracy: 0.7446\n",
      "Epoch 216/300\n",
      "603/603 [==============================] - 0s 610us/step - loss: 0.4961 - accuracy: 0.7437\n",
      "Epoch 217/300\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.4950 - accuracy: 0.7418\n",
      "Epoch 218/300\n",
      "603/603 [==============================] - 0s 694us/step - loss: 0.4962 - accuracy: 0.7451\n",
      "Epoch 219/300\n",
      "603/603 [==============================] - 0s 622us/step - loss: 0.4948 - accuracy: 0.7460\n",
      "Epoch 220/300\n",
      "603/603 [==============================] - 0s 639us/step - loss: 0.4992 - accuracy: 0.7426\n",
      "Epoch 221/300\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.4978 - accuracy: 0.7431\n",
      "Epoch 222/300\n",
      "603/603 [==============================] - 0s 701us/step - loss: 0.4967 - accuracy: 0.7462\n",
      "Epoch 223/300\n",
      "603/603 [==============================] - 0s 613us/step - loss: 0.4929 - accuracy: 0.7465\n",
      "Epoch 224/300\n",
      "603/603 [==============================] - 0s 598us/step - loss: 0.4959 - accuracy: 0.7433\n",
      "Epoch 225/300\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.4940 - accuracy: 0.7442\n",
      "Epoch 226/300\n",
      "603/603 [==============================] - 0s 606us/step - loss: 0.4978 - accuracy: 0.7465\n",
      "Epoch 227/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.4928 - accuracy: 0.7453\n",
      "Epoch 228/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.4905 - accuracy: 0.7467\n",
      "Epoch 229/300\n",
      "603/603 [==============================] - 0s 600us/step - loss: 0.5018 - accuracy: 0.7418\n",
      "Epoch 230/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.4911 - accuracy: 0.7470\n",
      "Epoch 231/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.4918 - accuracy: 0.7444\n",
      "Epoch 232/300\n",
      "603/603 [==============================] - 0s 639us/step - loss: 0.4904 - accuracy: 0.7452\n",
      "Epoch 233/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.4920 - accuracy: 0.7456\n",
      "Epoch 234/300\n",
      "603/603 [==============================] - 0s 617us/step - loss: 0.4960 - accuracy: 0.7432\n",
      "Epoch 235/300\n",
      "603/603 [==============================] - 0s 589us/step - loss: 0.4900 - accuracy: 0.7443\n",
      "Epoch 236/300\n",
      "603/603 [==============================] - 0s 591us/step - loss: 0.4904 - accuracy: 0.7454\n",
      "Epoch 237/300\n",
      "603/603 [==============================] - 0s 596us/step - loss: 0.4910 - accuracy: 0.7484\n",
      "Epoch 238/300\n",
      "603/603 [==============================] - 0s 589us/step - loss: 0.4952 - accuracy: 0.7438\n",
      "Epoch 239/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.4923 - accuracy: 0.7467\n",
      "Epoch 240/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.4901 - accuracy: 0.7422\n",
      "Epoch 241/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.4901 - accuracy: 0.7453\n",
      "Epoch 242/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.4954 - accuracy: 0.7449\n",
      "Epoch 243/300\n",
      "603/603 [==============================] - 0s 598us/step - loss: 0.4931 - accuracy: 0.7456\n",
      "Epoch 244/300\n",
      "603/603 [==============================] - 0s 589us/step - loss: 0.4889 - accuracy: 0.7492\n",
      "Epoch 245/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.4935 - accuracy: 0.7423\n",
      "Epoch 246/300\n",
      "603/603 [==============================] - 0s 593us/step - loss: 0.4872 - accuracy: 0.7470\n",
      "Epoch 247/300\n",
      "603/603 [==============================] - 0s 585us/step - loss: 0.4881 - accuracy: 0.7489\n",
      "Epoch 248/300\n",
      "603/603 [==============================] - 0s 603us/step - loss: 0.4867 - accuracy: 0.7478\n",
      "Epoch 249/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.4974 - accuracy: 0.7401\n",
      "Epoch 250/300\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.4908 - accuracy: 0.7441\n",
      "Epoch 251/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.4847 - accuracy: 0.7476\n",
      "Epoch 252/300\n",
      "603/603 [==============================] - 0s 590us/step - loss: 0.4870 - accuracy: 0.7461\n",
      "Epoch 253/300\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.4893 - accuracy: 0.7451\n",
      "Epoch 254/300\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.4931 - accuracy: 0.7411\n",
      "Epoch 255/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.4876 - accuracy: 0.7472\n",
      "Epoch 256/300\n",
      "603/603 [==============================] - 0s 598us/step - loss: 0.4914 - accuracy: 0.7464\n",
      "Epoch 257/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.4926 - accuracy: 0.7450\n",
      "Epoch 258/300\n",
      "603/603 [==============================] - 0s 607us/step - loss: 0.4905 - accuracy: 0.7449\n",
      "Epoch 259/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.4861 - accuracy: 0.7474\n",
      "Epoch 260/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.4904 - accuracy: 0.7466\n",
      "Epoch 261/300\n",
      "603/603 [==============================] - 0s 646us/step - loss: 0.4845 - accuracy: 0.7475\n",
      "Epoch 262/300\n",
      "603/603 [==============================] - 0s 648us/step - loss: 0.4869 - accuracy: 0.7457\n",
      "Epoch 263/300\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.4843 - accuracy: 0.7469\n",
      "Epoch 264/300\n",
      "603/603 [==============================] - 0s 631us/step - loss: 0.4844 - accuracy: 0.7468\n",
      "Epoch 265/300\n",
      "603/603 [==============================] - 0s 609us/step - loss: 0.4874 - accuracy: 0.7463\n",
      "Epoch 266/300\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.4849 - accuracy: 0.7465\n",
      "Epoch 267/300\n",
      "603/603 [==============================] - 0s 624us/step - loss: 0.4933 - accuracy: 0.7447\n",
      "Epoch 268/300\n",
      "603/603 [==============================] - 0s 604us/step - loss: 0.4849 - accuracy: 0.7479\n",
      "Epoch 269/300\n",
      "603/603 [==============================] - 0s 640us/step - loss: 0.4832 - accuracy: 0.7498\n",
      "Epoch 270/300\n",
      "603/603 [==============================] - 0s 621us/step - loss: 0.4889 - accuracy: 0.7460\n",
      "Epoch 271/300\n",
      "603/603 [==============================] - 0s 605us/step - loss: 0.4784 - accuracy: 0.7494\n",
      "Epoch 272/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.4804 - accuracy: 0.7496\n",
      "Epoch 273/300\n",
      "603/603 [==============================] - 0s 593us/step - loss: 0.4825 - accuracy: 0.7460\n",
      "Epoch 274/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.4869 - accuracy: 0.7464\n",
      "Epoch 275/300\n",
      "603/603 [==============================] - 0s 607us/step - loss: 0.4803 - accuracy: 0.7483\n",
      "Epoch 276/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.4896 - accuracy: 0.7455\n",
      "Epoch 277/300\n",
      "603/603 [==============================] - 0s 614us/step - loss: 0.4868 - accuracy: 0.7485\n",
      "Epoch 278/300\n",
      "603/603 [==============================] - 0s 596us/step - loss: 0.4846 - accuracy: 0.7484\n",
      "Epoch 279/300\n",
      "603/603 [==============================] - 0s 588us/step - loss: 0.4812 - accuracy: 0.7462\n",
      "Epoch 280/300\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.4884 - accuracy: 0.7471\n",
      "Epoch 281/300\n",
      "603/603 [==============================] - 0s 614us/step - loss: 0.4837 - accuracy: 0.7487\n",
      "Epoch 282/300\n",
      "603/603 [==============================] - 0s 615us/step - loss: 0.4835 - accuracy: 0.7471\n",
      "Epoch 283/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.4866 - accuracy: 0.7476\n",
      "Epoch 284/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.4849 - accuracy: 0.7503\n",
      "Epoch 285/300\n",
      "603/603 [==============================] - 0s 596us/step - loss: 0.4835 - accuracy: 0.7454\n",
      "Epoch 286/300\n",
      "603/603 [==============================] - 0s 596us/step - loss: 0.4811 - accuracy: 0.7471\n",
      "Epoch 287/300\n",
      "603/603 [==============================] - 0s 593us/step - loss: 0.4840 - accuracy: 0.7471\n",
      "Epoch 288/300\n",
      "603/603 [==============================] - 0s 599us/step - loss: 0.4751 - accuracy: 0.7527\n",
      "Epoch 289/300\n",
      "603/603 [==============================] - 0s 595us/step - loss: 0.4835 - accuracy: 0.7506\n",
      "Epoch 290/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.4802 - accuracy: 0.7483\n",
      "Epoch 291/300\n",
      "603/603 [==============================] - 0s 592us/step - loss: 0.4815 - accuracy: 0.7496\n",
      "Epoch 292/300\n",
      "603/603 [==============================] - 0s 594us/step - loss: 0.4860 - accuracy: 0.7473\n",
      "Epoch 293/300\n",
      "603/603 [==============================] - 0s 614us/step - loss: 0.4768 - accuracy: 0.7499\n",
      "Epoch 294/300\n",
      "603/603 [==============================] - 0s 603us/step - loss: 0.4874 - accuracy: 0.7450\n",
      "Epoch 295/300\n",
      "603/603 [==============================] - 0s 602us/step - loss: 0.4854 - accuracy: 0.7471\n",
      "Epoch 296/300\n",
      "603/603 [==============================] - 0s 617us/step - loss: 0.4814 - accuracy: 0.7484\n",
      "Epoch 297/300\n",
      "603/603 [==============================] - 0s 648us/step - loss: 0.4792 - accuracy: 0.7497\n",
      "Epoch 298/300\n",
      "603/603 [==============================] - 0s 621us/step - loss: 0.4767 - accuracy: 0.7519\n",
      "Epoch 299/300\n",
      "603/603 [==============================] - 0s 597us/step - loss: 0.4820 - accuracy: 0.7461\n",
      "Epoch 300/300\n",
      "603/603 [==============================] - 0s 601us/step - loss: 0.4854 - accuracy: 0.7476\n",
      "129/129 [==============================] - 0s 436us/step - loss: 1.1267 - accuracy: 0.6550\n",
      "[1.1266918182373047, 0.6550218462944031]\n",
      "129/129 [==============================] - 0s 342us/step\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58      1672\n",
      "           1       0.72      0.69      0.70      2450\n",
      "\n",
      "    accuracy                           0.66      4122\n",
      "   macro avg       0.64      0.65      0.64      4122\n",
      "weighted avg       0.66      0.66      0.66      4122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0 , count_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "18154357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19288, 32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1.shape\n",
    "\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace = True)\n",
    "df_test_over = pd.concat([df_class_1_over, df_class_0 ],axis = 0)\n",
    "df_test_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4e9b5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_over['HTO_classification.global'].value_counts()\n",
    "X_train = df_test_over.drop(\"HTO_classification.global\", axis = \"columns\")\n",
    "y_train = df_test_over[\"HTO_classification.global\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fafd9da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9644, 32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2ba9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1163f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184d508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182dc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606efe04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "00ea1ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7112\n",
       "1    3556\n",
       "Name: HTO_classification.global, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_under['HTO_classification.global'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5b010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "be6d1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_test_under.drop(\"HTO_classification.global\", axis = \"columns\")\n",
    "y_train = df_test_under[\"HTO_classification.global\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a823e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73739f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508091d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7aed8954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6006\n",
       "1    6006\n",
       "Name: HTO_classification.global, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy = \"minority\")\n",
    "X_sm, y_sm = smote.fit_resample(X,y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "234952c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm,y_sm, test_size = 0.2, random_state =15,stratify = y_sm )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ab8ace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "603/603 [==============================] - 1s 688us/step - loss: 2.7737 - accuracy: 0.6185\n",
      "Epoch 2/300\n",
      "603/603 [==============================] - 0s 695us/step - loss: 0.9224 - accuracy: 0.6383\n",
      "Epoch 3/300\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.7926 - accuracy: 0.6460\n",
      "Epoch 4/300\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.7453 - accuracy: 0.6546\n",
      "Epoch 5/300\n",
      "603/603 [==============================] - 0s 659us/step - loss: 0.7082 - accuracy: 0.6562\n",
      "Epoch 6/300\n",
      "603/603 [==============================] - 0s 657us/step - loss: 0.6793 - accuracy: 0.6585\n",
      "Epoch 7/300\n",
      "603/603 [==============================] - 0s 669us/step - loss: 0.6736 - accuracy: 0.6576\n",
      "Epoch 8/300\n",
      "603/603 [==============================] - 0s 668us/step - loss: 0.6234 - accuracy: 0.6697\n",
      "Epoch 9/300\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.6196 - accuracy: 0.6738\n",
      "Epoch 10/300\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.6167 - accuracy: 0.6758\n",
      "Epoch 11/300\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.6038 - accuracy: 0.6791\n",
      "Epoch 12/300\n",
      "603/603 [==============================] - 0s 683us/step - loss: 0.6057 - accuracy: 0.6762\n",
      "Epoch 13/300\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.5893 - accuracy: 0.6877\n",
      "Epoch 14/300\n",
      "603/603 [==============================] - 0s 664us/step - loss: 0.5938 - accuracy: 0.6856\n",
      "Epoch 15/300\n",
      "603/603 [==============================] - 0s 725us/step - loss: 0.5925 - accuracy: 0.6852\n",
      "Epoch 16/300\n",
      "603/603 [==============================] - 0s 734us/step - loss: 0.5871 - accuracy: 0.6909\n",
      "Epoch 17/300\n",
      "603/603 [==============================] - 0s 656us/step - loss: 0.5853 - accuracy: 0.6928\n",
      "Epoch 18/300\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.5916 - accuracy: 0.6893\n",
      "Epoch 19/300\n",
      "603/603 [==============================] - 0s 670us/step - loss: 0.5886 - accuracy: 0.6917\n",
      "Epoch 20/300\n",
      "603/603 [==============================] - 0s 679us/step - loss: 0.5879 - accuracy: 0.6886\n",
      "Epoch 21/300\n",
      "603/603 [==============================] - 0s 674us/step - loss: 0.5881 - accuracy: 0.6893\n",
      "Epoch 22/300\n",
      "603/603 [==============================] - 0s 667us/step - loss: 0.5838 - accuracy: 0.6940\n",
      "Epoch 23/300\n",
      "603/603 [==============================] - 0s 701us/step - loss: 0.5871 - accuracy: 0.6913\n",
      "Epoch 24/300\n",
      "603/603 [==============================] - 1s 835us/step - loss: 0.5878 - accuracy: 0.6884\n",
      "Epoch 25/300\n",
      "603/603 [==============================] - 0s 729us/step - loss: 0.5832 - accuracy: 0.6933\n",
      "Epoch 26/300\n",
      "603/603 [==============================] - 0s 754us/step - loss: 0.5803 - accuracy: 0.6960\n",
      "Epoch 27/300\n",
      "603/603 [==============================] - 0s 723us/step - loss: 0.5785 - accuracy: 0.6976\n",
      "Epoch 28/300\n",
      "603/603 [==============================] - 0s 702us/step - loss: 0.5782 - accuracy: 0.7001\n",
      "Epoch 29/300\n",
      "603/603 [==============================] - 0s 804us/step - loss: 0.5759 - accuracy: 0.6992\n",
      "Epoch 30/300\n",
      "603/603 [==============================] - 0s 710us/step - loss: 0.5772 - accuracy: 0.6991\n",
      "Epoch 31/300\n",
      "603/603 [==============================] - 1s 831us/step - loss: 0.5758 - accuracy: 0.6997\n",
      "Epoch 32/300\n",
      "603/603 [==============================] - 0s 786us/step - loss: 0.5772 - accuracy: 0.7009\n",
      "Epoch 33/300\n",
      "603/603 [==============================] - 1s 882us/step - loss: 0.5747 - accuracy: 0.6999\n",
      "Epoch 34/300\n",
      "603/603 [==============================] - 0s 772us/step - loss: 0.5739 - accuracy: 0.7003\n",
      "Epoch 35/300\n",
      "603/603 [==============================] - 0s 802us/step - loss: 0.5734 - accuracy: 0.7033\n",
      "Epoch 36/300\n",
      "603/603 [==============================] - 0s 692us/step - loss: 0.5736 - accuracy: 0.7035\n",
      "Epoch 37/300\n",
      "603/603 [==============================] - 0s 659us/step - loss: 0.5737 - accuracy: 0.7024\n",
      "Epoch 38/300\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.5725 - accuracy: 0.7018\n",
      "Epoch 39/300\n",
      "603/603 [==============================] - 0s 661us/step - loss: 0.5716 - accuracy: 0.7030\n",
      "Epoch 40/300\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.5691 - accuracy: 0.7061\n",
      "Epoch 41/300\n",
      "603/603 [==============================] - 0s 655us/step - loss: 0.5715 - accuracy: 0.7031\n",
      "Epoch 42/300\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.5700 - accuracy: 0.7050\n",
      "Epoch 43/300\n",
      "603/603 [==============================] - 0s 654us/step - loss: 0.5689 - accuracy: 0.7048\n",
      "Epoch 44/300\n",
      "603/603 [==============================] - 0s 712us/step - loss: 0.5688 - accuracy: 0.7046\n",
      "Epoch 45/300\n",
      "603/603 [==============================] - 0s 774us/step - loss: 0.5683 - accuracy: 0.7054\n",
      "Epoch 46/300\n",
      "603/603 [==============================] - 0s 739us/step - loss: 0.5659 - accuracy: 0.7103\n",
      "Epoch 47/300\n",
      "603/603 [==============================] - 0s 771us/step - loss: 0.5676 - accuracy: 0.7080\n",
      "Epoch 48/300\n",
      "603/603 [==============================] - 0s 745us/step - loss: 0.5652 - accuracy: 0.7059\n",
      "Epoch 49/300\n",
      "603/603 [==============================] - 0s 711us/step - loss: 0.5647 - accuracy: 0.7080\n",
      "Epoch 50/300\n",
      "603/603 [==============================] - 0s 779us/step - loss: 0.5640 - accuracy: 0.7104\n",
      "Epoch 51/300\n",
      "603/603 [==============================] - 1s 985us/step - loss: 0.5623 - accuracy: 0.7106\n",
      "Epoch 52/300\n",
      "603/603 [==============================] - 0s 769us/step - loss: 0.5642 - accuracy: 0.7076\n",
      "Epoch 53/300\n",
      "603/603 [==============================] - 0s 761us/step - loss: 0.5627 - accuracy: 0.7108\n",
      "Epoch 54/300\n",
      "603/603 [==============================] - 0s 776us/step - loss: 0.5612 - accuracy: 0.7140\n",
      "Epoch 55/300\n",
      "603/603 [==============================] - 0s 723us/step - loss: 0.5638 - accuracy: 0.7088\n",
      "Epoch 56/300\n",
      "603/603 [==============================] - 0s 718us/step - loss: 0.5608 - accuracy: 0.7123\n",
      "Epoch 57/300\n",
      "603/603 [==============================] - 0s 688us/step - loss: 0.5607 - accuracy: 0.7130\n",
      "Epoch 58/300\n",
      "603/603 [==============================] - 0s 690us/step - loss: 0.5594 - accuracy: 0.7124\n",
      "Epoch 59/300\n",
      "603/603 [==============================] - 0s 669us/step - loss: 0.5605 - accuracy: 0.7127\n",
      "Epoch 60/300\n",
      "603/603 [==============================] - 0s 665us/step - loss: 0.5604 - accuracy: 0.7114\n",
      "Epoch 61/300\n",
      "603/603 [==============================] - 0s 714us/step - loss: 0.5579 - accuracy: 0.7156\n",
      "Epoch 62/300\n",
      "603/603 [==============================] - 0s 684us/step - loss: 0.5589 - accuracy: 0.7128\n",
      "Epoch 63/300\n",
      "603/603 [==============================] - 0s 668us/step - loss: 0.5581 - accuracy: 0.7150\n",
      "Epoch 64/300\n",
      "603/603 [==============================] - 0s 741us/step - loss: 0.5575 - accuracy: 0.7151\n",
      "Epoch 65/300\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.5584 - accuracy: 0.7143\n",
      "Epoch 66/300\n",
      "603/603 [==============================] - 0s 765us/step - loss: 0.5551 - accuracy: 0.7186\n",
      "Epoch 67/300\n",
      "603/603 [==============================] - 0s 742us/step - loss: 0.5567 - accuracy: 0.7156\n",
      "Epoch 68/300\n",
      "603/603 [==============================] - 0s 746us/step - loss: 0.5553 - accuracy: 0.7155\n",
      "Epoch 69/300\n",
      "603/603 [==============================] - 0s 741us/step - loss: 0.5555 - accuracy: 0.7160\n",
      "Epoch 70/300\n",
      "603/603 [==============================] - 0s 656us/step - loss: 0.5546 - accuracy: 0.7173\n",
      "Epoch 71/300\n",
      "603/603 [==============================] - 0s 728us/step - loss: 0.5543 - accuracy: 0.7172\n",
      "Epoch 72/300\n",
      "603/603 [==============================] - 0s 658us/step - loss: 0.5531 - accuracy: 0.7181\n",
      "Epoch 73/300\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.5544 - accuracy: 0.7174\n",
      "Epoch 74/300\n",
      "603/603 [==============================] - 0s 661us/step - loss: 0.5539 - accuracy: 0.7202\n",
      "Epoch 75/300\n",
      "603/603 [==============================] - 0s 655us/step - loss: 0.5529 - accuracy: 0.7185\n",
      "Epoch 76/300\n",
      "603/603 [==============================] - 0s 670us/step - loss: 0.5521 - accuracy: 0.7170\n",
      "Epoch 77/300\n",
      "603/603 [==============================] - 0s 658us/step - loss: 0.5524 - accuracy: 0.7181\n",
      "Epoch 78/300\n",
      "603/603 [==============================] - 0s 662us/step - loss: 0.5512 - accuracy: 0.7201\n",
      "Epoch 79/300\n",
      "603/603 [==============================] - 0s 645us/step - loss: 0.5510 - accuracy: 0.7200\n",
      "Epoch 80/300\n",
      "603/603 [==============================] - 0s 643us/step - loss: 0.5506 - accuracy: 0.7208\n",
      "Epoch 81/300\n",
      "603/603 [==============================] - 0s 644us/step - loss: 0.5511 - accuracy: 0.7222\n",
      "Epoch 82/300\n",
      "603/603 [==============================] - 0s 643us/step - loss: 0.5498 - accuracy: 0.7186\n",
      "Epoch 83/300\n",
      "603/603 [==============================] - 0s 656us/step - loss: 0.5498 - accuracy: 0.7200\n",
      "Epoch 84/300\n",
      "603/603 [==============================] - 0s 654us/step - loss: 0.5507 - accuracy: 0.7187\n",
      "Epoch 85/300\n",
      "603/603 [==============================] - 0s 653us/step - loss: 0.5478 - accuracy: 0.7215\n",
      "Epoch 86/300\n",
      "603/603 [==============================] - 0s 652us/step - loss: 0.5483 - accuracy: 0.7190\n",
      "Epoch 87/300\n",
      "603/603 [==============================] - 0s 648us/step - loss: 0.5482 - accuracy: 0.7223\n",
      "Epoch 88/300\n",
      "603/603 [==============================] - 0s 639us/step - loss: 0.5479 - accuracy: 0.7225\n",
      "Epoch 89/300\n",
      "603/603 [==============================] - 0s 659us/step - loss: 0.5467 - accuracy: 0.7216\n",
      "Epoch 90/300\n",
      "603/603 [==============================] - 0s 661us/step - loss: 0.5462 - accuracy: 0.7224\n",
      "Epoch 91/300\n",
      "603/603 [==============================] - 0s 665us/step - loss: 0.5455 - accuracy: 0.7229\n",
      "Epoch 92/300\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.5447 - accuracy: 0.7240\n",
      "Epoch 93/300\n",
      "603/603 [==============================] - 0s 682us/step - loss: 0.5463 - accuracy: 0.7231\n",
      "Epoch 94/300\n",
      "603/603 [==============================] - 0s 825us/step - loss: 0.5454 - accuracy: 0.7218\n",
      "Epoch 95/300\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.5451 - accuracy: 0.7227\n",
      "Epoch 96/300\n",
      "603/603 [==============================] - 0s 669us/step - loss: 0.5445 - accuracy: 0.7237\n",
      "Epoch 97/300\n",
      "603/603 [==============================] - 0s 725us/step - loss: 0.5431 - accuracy: 0.7222\n",
      "Epoch 98/300\n",
      "603/603 [==============================] - 0s 674us/step - loss: 0.5424 - accuracy: 0.7233\n",
      "Epoch 99/300\n",
      "603/603 [==============================] - 0s 701us/step - loss: 0.5432 - accuracy: 0.7239\n",
      "Epoch 100/300\n",
      "603/603 [==============================] - 0s 656us/step - loss: 0.5433 - accuracy: 0.7242\n",
      "Epoch 101/300\n",
      "603/603 [==============================] - 0s 683us/step - loss: 0.5423 - accuracy: 0.7255\n",
      "Epoch 102/300\n",
      "603/603 [==============================] - 0s 648us/step - loss: 0.5413 - accuracy: 0.7239\n",
      "Epoch 103/300\n",
      "603/603 [==============================] - 0s 784us/step - loss: 0.5419 - accuracy: 0.7259\n",
      "Epoch 104/300\n",
      "603/603 [==============================] - 0s 695us/step - loss: 0.5399 - accuracy: 0.7259\n",
      "Epoch 105/300\n",
      "603/603 [==============================] - 0s 690us/step - loss: 0.5406 - accuracy: 0.7268\n",
      "Epoch 106/300\n",
      "603/603 [==============================] - 0s 619us/step - loss: 0.5377 - accuracy: 0.7258\n",
      "Epoch 107/300\n",
      "603/603 [==============================] - 0s 662us/step - loss: 0.5380 - accuracy: 0.7251\n",
      "Epoch 108/300\n",
      "603/603 [==============================] - 0s 741us/step - loss: 0.5365 - accuracy: 0.7283\n",
      "Epoch 109/300\n",
      "603/603 [==============================] - 0s 658us/step - loss: 0.5378 - accuracy: 0.7279\n",
      "Epoch 110/300\n",
      "603/603 [==============================] - 0s 677us/step - loss: 0.5380 - accuracy: 0.7280\n",
      "Epoch 111/300\n",
      "603/603 [==============================] - 0s 745us/step - loss: 0.5373 - accuracy: 0.7300\n",
      "Epoch 112/300\n",
      "603/603 [==============================] - 0s 674us/step - loss: 0.5376 - accuracy: 0.7279\n",
      "Epoch 113/300\n",
      "603/603 [==============================] - 0s 740us/step - loss: 0.5361 - accuracy: 0.7271\n",
      "Epoch 114/300\n",
      "603/603 [==============================] - 1s 872us/step - loss: 0.5360 - accuracy: 0.7308\n",
      "Epoch 115/300\n",
      "603/603 [==============================] - 1s 941us/step - loss: 0.5368 - accuracy: 0.7283\n",
      "Epoch 116/300\n",
      "603/603 [==============================] - 0s 704us/step - loss: 0.5357 - accuracy: 0.7314\n",
      "Epoch 117/300\n",
      "603/603 [==============================] - 0s 784us/step - loss: 0.5342 - accuracy: 0.7296\n",
      "Epoch 118/300\n",
      "603/603 [==============================] - 0s 727us/step - loss: 0.5343 - accuracy: 0.7287\n",
      "Epoch 119/300\n",
      "603/603 [==============================] - 0s 815us/step - loss: 0.5347 - accuracy: 0.7288\n",
      "Epoch 120/300\n",
      "603/603 [==============================] - 0s 711us/step - loss: 0.5329 - accuracy: 0.7297\n",
      "Epoch 121/300\n",
      "603/603 [==============================] - 0s 657us/step - loss: 0.5320 - accuracy: 0.7304\n",
      "Epoch 122/300\n",
      "603/603 [==============================] - 0s 662us/step - loss: 0.5321 - accuracy: 0.7309\n",
      "Epoch 123/300\n",
      "603/603 [==============================] - 0s 652us/step - loss: 0.5339 - accuracy: 0.7289\n",
      "Epoch 124/300\n",
      "603/603 [==============================] - 0s 664us/step - loss: 0.5330 - accuracy: 0.7320\n",
      "Epoch 125/300\n",
      "603/603 [==============================] - 0s 654us/step - loss: 0.5331 - accuracy: 0.7324\n",
      "Epoch 126/300\n",
      "603/603 [==============================] - 0s 651us/step - loss: 0.5318 - accuracy: 0.7311\n",
      "Epoch 127/300\n",
      "603/603 [==============================] - 0s 694us/step - loss: 0.5318 - accuracy: 0.7304\n",
      "Epoch 128/300\n",
      "603/603 [==============================] - 0s 662us/step - loss: 0.5308 - accuracy: 0.7330\n",
      "Epoch 129/300\n",
      "603/603 [==============================] - 0s 747us/step - loss: 0.5315 - accuracy: 0.7301\n",
      "Epoch 130/300\n",
      "603/603 [==============================] - 0s 763us/step - loss: 0.5296 - accuracy: 0.7329\n",
      "Epoch 131/300\n",
      "603/603 [==============================] - 0s 663us/step - loss: 0.5294 - accuracy: 0.7304\n",
      "Epoch 132/300\n",
      "603/603 [==============================] - 0s 678us/step - loss: 0.5324 - accuracy: 0.7313\n",
      "Epoch 133/300\n",
      "603/603 [==============================] - 0s 696us/step - loss: 0.5273 - accuracy: 0.7326\n",
      "Epoch 134/300\n",
      "603/603 [==============================] - 0s 678us/step - loss: 0.5295 - accuracy: 0.7324\n",
      "Epoch 135/300\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.5287 - accuracy: 0.7367\n",
      "Epoch 136/300\n",
      "603/603 [==============================] - 0s 705us/step - loss: 0.5255 - accuracy: 0.7338\n",
      "Epoch 137/300\n",
      "603/603 [==============================] - 0s 706us/step - loss: 0.5299 - accuracy: 0.7312\n",
      "Epoch 138/300\n",
      "603/603 [==============================] - 0s 686us/step - loss: 0.5272 - accuracy: 0.7338\n",
      "Epoch 139/300\n",
      "603/603 [==============================] - 0s 732us/step - loss: 0.5270 - accuracy: 0.7323\n",
      "Epoch 140/300\n",
      "603/603 [==============================] - 0s 738us/step - loss: 0.5266 - accuracy: 0.7339\n",
      "Epoch 141/300\n",
      "603/603 [==============================] - 0s 796us/step - loss: 0.5274 - accuracy: 0.7323\n",
      "Epoch 142/300\n",
      "603/603 [==============================] - 0s 750us/step - loss: 0.5250 - accuracy: 0.7370\n",
      "Epoch 143/300\n",
      "603/603 [==============================] - 0s 798us/step - loss: 0.5268 - accuracy: 0.7334\n",
      "Epoch 144/300\n",
      "603/603 [==============================] - 0s 797us/step - loss: 0.5252 - accuracy: 0.7362\n",
      "Epoch 145/300\n",
      "603/603 [==============================] - 0s 753us/step - loss: 0.5249 - accuracy: 0.7366\n",
      "Epoch 146/300\n",
      "603/603 [==============================] - 0s 709us/step - loss: 0.5232 - accuracy: 0.7349\n",
      "Epoch 147/300\n",
      "603/603 [==============================] - 0s 749us/step - loss: 0.5251 - accuracy: 0.7341\n",
      "Epoch 148/300\n",
      "603/603 [==============================] - 0s 762us/step - loss: 0.5244 - accuracy: 0.7351\n",
      "Epoch 149/300\n",
      "603/603 [==============================] - 0s 676us/step - loss: 0.5242 - accuracy: 0.7354\n",
      "Epoch 150/300\n",
      "603/603 [==============================] - 0s 725us/step - loss: 0.5206 - accuracy: 0.7385\n",
      "Epoch 151/300\n",
      "603/603 [==============================] - 0s 728us/step - loss: 0.5203 - accuracy: 0.7404\n",
      "Epoch 152/300\n",
      "603/603 [==============================] - 0s 692us/step - loss: 0.5213 - accuracy: 0.7352\n",
      "Epoch 153/300\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.5210 - accuracy: 0.7390\n",
      "Epoch 154/300\n",
      "603/603 [==============================] - 0s 671us/step - loss: 0.5219 - accuracy: 0.7371\n",
      "Epoch 155/300\n",
      "603/603 [==============================] - 0s 674us/step - loss: 0.5204 - accuracy: 0.7374\n",
      "Epoch 156/300\n",
      "603/603 [==============================] - 0s 664us/step - loss: 0.5202 - accuracy: 0.7373\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 675us/step - loss: 0.5208 - accuracy: 0.7363\n",
      "Epoch 158/300\n",
      "603/603 [==============================] - 0s 659us/step - loss: 0.5216 - accuracy: 0.7375\n",
      "Epoch 159/300\n",
      "603/603 [==============================] - 0s 661us/step - loss: 0.5196 - accuracy: 0.7369\n",
      "Epoch 160/300\n",
      "603/603 [==============================] - 0s 696us/step - loss: 0.5207 - accuracy: 0.7374\n",
      "Epoch 161/300\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.5187 - accuracy: 0.7401\n",
      "Epoch 162/300\n",
      "603/603 [==============================] - 0s 687us/step - loss: 0.5184 - accuracy: 0.7380\n",
      "Epoch 163/300\n",
      "603/603 [==============================] - 0s 679us/step - loss: 0.5172 - accuracy: 0.7385\n",
      "Epoch 164/300\n",
      "603/603 [==============================] - 0s 657us/step - loss: 0.5194 - accuracy: 0.7385\n",
      "Epoch 165/300\n",
      "603/603 [==============================] - 0s 822us/step - loss: 0.5155 - accuracy: 0.7405\n",
      "Epoch 166/300\n",
      "603/603 [==============================] - 0s 670us/step - loss: 0.5160 - accuracy: 0.7400\n",
      "Epoch 167/300\n",
      "603/603 [==============================] - 0s 706us/step - loss: 0.5181 - accuracy: 0.7384\n",
      "Epoch 168/300\n",
      "603/603 [==============================] - 0s 704us/step - loss: 0.5158 - accuracy: 0.7407\n",
      "Epoch 169/300\n",
      "603/603 [==============================] - 0s 675us/step - loss: 0.5169 - accuracy: 0.7390\n",
      "Epoch 170/300\n",
      "603/603 [==============================] - 0s 665us/step - loss: 0.5154 - accuracy: 0.7410\n",
      "Epoch 171/300\n",
      "603/603 [==============================] - 0s 674us/step - loss: 0.5156 - accuracy: 0.7391\n",
      "Epoch 172/300\n",
      "603/603 [==============================] - 0s 660us/step - loss: 0.5126 - accuracy: 0.7442\n",
      "Epoch 173/300\n",
      "603/603 [==============================] - 0s 657us/step - loss: 0.5133 - accuracy: 0.7422\n",
      "Epoch 174/300\n",
      "603/603 [==============================] - 0s 662us/step - loss: 0.5151 - accuracy: 0.7386\n",
      "Epoch 175/300\n",
      "603/603 [==============================] - 0s 663us/step - loss: 0.5177 - accuracy: 0.7407\n",
      "Epoch 176/300\n",
      "603/603 [==============================] - 0s 711us/step - loss: 0.5138 - accuracy: 0.7407\n",
      "Epoch 177/300\n",
      "603/603 [==============================] - 0s 656us/step - loss: 0.5133 - accuracy: 0.7433\n",
      "Epoch 178/300\n",
      "603/603 [==============================] - 0s 709us/step - loss: 0.5132 - accuracy: 0.7415\n",
      "Epoch 179/300\n",
      "603/603 [==============================] - 0s 691us/step - loss: 0.5120 - accuracy: 0.7429\n",
      "Epoch 180/300\n",
      "603/603 [==============================] - 0s 667us/step - loss: 0.5119 - accuracy: 0.7422\n",
      "Epoch 181/300\n",
      "603/603 [==============================] - 0s 724us/step - loss: 0.5135 - accuracy: 0.7424\n",
      "Epoch 182/300\n",
      "603/603 [==============================] - 0s 721us/step - loss: 0.5109 - accuracy: 0.7425\n",
      "Epoch 183/300\n",
      "603/603 [==============================] - 0s 711us/step - loss: 0.5099 - accuracy: 0.7428\n",
      "Epoch 184/300\n",
      "603/603 [==============================] - 0s 729us/step - loss: 0.5121 - accuracy: 0.7421\n",
      "Epoch 185/300\n",
      "603/603 [==============================] - 0s 685us/step - loss: 0.5137 - accuracy: 0.7418\n",
      "Epoch 186/300\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.5122 - accuracy: 0.7434\n",
      "Epoch 187/300\n",
      "603/603 [==============================] - 0s 664us/step - loss: 0.5132 - accuracy: 0.7437\n",
      "Epoch 188/300\n",
      "603/603 [==============================] - 1s 888us/step - loss: 0.5094 - accuracy: 0.7424\n",
      "Epoch 189/300\n",
      "603/603 [==============================] - 0s 722us/step - loss: 0.5112 - accuracy: 0.7432\n",
      "Epoch 190/300\n",
      "603/603 [==============================] - 0s 687us/step - loss: 0.5067 - accuracy: 0.7451\n",
      "Epoch 191/300\n",
      "603/603 [==============================] - 0s 671us/step - loss: 0.5116 - accuracy: 0.7440\n",
      "Epoch 192/300\n",
      "603/603 [==============================] - 0s 676us/step - loss: 0.5089 - accuracy: 0.7439\n",
      "Epoch 193/300\n",
      "603/603 [==============================] - 0s 720us/step - loss: 0.5083 - accuracy: 0.7461\n",
      "Epoch 194/300\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.5088 - accuracy: 0.7436\n",
      "Epoch 195/300\n",
      "603/603 [==============================] - 0s 677us/step - loss: 0.5078 - accuracy: 0.7455\n",
      "Epoch 196/300\n",
      "603/603 [==============================] - 0s 697us/step - loss: 0.5072 - accuracy: 0.7451\n",
      "Epoch 197/300\n",
      "603/603 [==============================] - 0s 690us/step - loss: 0.5111 - accuracy: 0.7433\n",
      "Epoch 198/300\n",
      "603/603 [==============================] - 0s 675us/step - loss: 0.5077 - accuracy: 0.7453\n",
      "Epoch 199/300\n",
      "603/603 [==============================] - 0s 663us/step - loss: 0.5087 - accuracy: 0.7433\n",
      "Epoch 200/300\n",
      "603/603 [==============================] - 0s 737us/step - loss: 0.5056 - accuracy: 0.7475\n",
      "Epoch 201/300\n",
      "603/603 [==============================] - 0s 708us/step - loss: 0.5059 - accuracy: 0.7461\n",
      "Epoch 202/300\n",
      "603/603 [==============================] - 0s 700us/step - loss: 0.5060 - accuracy: 0.7474\n",
      "Epoch 203/300\n",
      "603/603 [==============================] - 0s 678us/step - loss: 0.5080 - accuracy: 0.7458\n",
      "Epoch 204/300\n",
      "603/603 [==============================] - 0s 694us/step - loss: 0.5056 - accuracy: 0.7471\n",
      "Epoch 205/300\n",
      "603/603 [==============================] - 0s 739us/step - loss: 0.5097 - accuracy: 0.7429\n",
      "Epoch 206/300\n",
      "603/603 [==============================] - 0s 729us/step - loss: 0.5029 - accuracy: 0.7488\n",
      "Epoch 207/300\n",
      "603/603 [==============================] - 0s 671us/step - loss: 0.5053 - accuracy: 0.7454\n",
      "Epoch 208/300\n",
      "603/603 [==============================] - 0s 673us/step - loss: 0.5076 - accuracy: 0.7439\n",
      "Epoch 209/300\n",
      "603/603 [==============================] - 0s 717us/step - loss: 0.5051 - accuracy: 0.7470\n",
      "Epoch 210/300\n",
      "603/603 [==============================] - 0s 695us/step - loss: 0.5060 - accuracy: 0.7446\n",
      "Epoch 211/300\n",
      "603/603 [==============================] - 0s 726us/step - loss: 0.5073 - accuracy: 0.7468\n",
      "Epoch 212/300\n",
      "603/603 [==============================] - 0s 701us/step - loss: 0.5054 - accuracy: 0.7470\n",
      "Epoch 213/300\n",
      "603/603 [==============================] - 0s 792us/step - loss: 0.5051 - accuracy: 0.7457\n",
      "Epoch 214/300\n",
      "603/603 [==============================] - 0s 744us/step - loss: 0.5024 - accuracy: 0.7469\n",
      "Epoch 215/300\n",
      "603/603 [==============================] - 0s 782us/step - loss: 0.5047 - accuracy: 0.7475\n",
      "Epoch 216/300\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.5030 - accuracy: 0.7480\n",
      "Epoch 217/300\n",
      "603/603 [==============================] - 1s 944us/step - loss: 0.5065 - accuracy: 0.7468\n",
      "Epoch 218/300\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.5008 - accuracy: 0.7498\n",
      "Epoch 219/300\n",
      "603/603 [==============================] - 0s 690us/step - loss: 0.5017 - accuracy: 0.7493\n",
      "Epoch 220/300\n",
      "603/603 [==============================] - 0s 713us/step - loss: 0.5030 - accuracy: 0.7470\n",
      "Epoch 221/300\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.5026 - accuracy: 0.7480\n",
      "Epoch 222/300\n",
      "603/603 [==============================] - 0s 668us/step - loss: 0.5035 - accuracy: 0.7480\n",
      "Epoch 223/300\n",
      "603/603 [==============================] - 0s 659us/step - loss: 0.5010 - accuracy: 0.7517\n",
      "Epoch 224/300\n",
      "603/603 [==============================] - 0s 680us/step - loss: 0.5022 - accuracy: 0.7488\n",
      "Epoch 225/300\n",
      "603/603 [==============================] - 0s 698us/step - loss: 0.5035 - accuracy: 0.7465\n",
      "Epoch 226/300\n",
      "603/603 [==============================] - 0s 708us/step - loss: 0.5023 - accuracy: 0.7499\n",
      "Epoch 227/300\n",
      "603/603 [==============================] - 1s 926us/step - loss: 0.5011 - accuracy: 0.7503\n",
      "Epoch 228/300\n",
      "603/603 [==============================] - 0s 673us/step - loss: 0.5044 - accuracy: 0.7476\n",
      "Epoch 229/300\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.5008 - accuracy: 0.7476\n",
      "Epoch 230/300\n",
      "603/603 [==============================] - 0s 671us/step - loss: 0.4998 - accuracy: 0.7498\n",
      "Epoch 231/300\n",
      "603/603 [==============================] - 0s 656us/step - loss: 0.5035 - accuracy: 0.7478\n",
      "Epoch 232/300\n",
      "603/603 [==============================] - 0s 653us/step - loss: 0.5105 - accuracy: 0.7465\n",
      "Epoch 233/300\n",
      "603/603 [==============================] - 0s 650us/step - loss: 0.4969 - accuracy: 0.7489\n",
      "Epoch 234/300\n",
      "603/603 [==============================] - 0s 784us/step - loss: 0.4986 - accuracy: 0.7507\n",
      "Epoch 235/300\n",
      "603/603 [==============================] - 0s 725us/step - loss: 0.4970 - accuracy: 0.7510\n",
      "Epoch 236/300\n",
      "603/603 [==============================] - 0s 758us/step - loss: 0.5048 - accuracy: 0.7473\n",
      "Epoch 237/300\n",
      "603/603 [==============================] - 0s 730us/step - loss: 0.5004 - accuracy: 0.7490\n",
      "Epoch 238/300\n",
      "603/603 [==============================] - 0s 692us/step - loss: 0.4978 - accuracy: 0.7515\n",
      "Epoch 239/300\n",
      "603/603 [==============================] - 0s 701us/step - loss: 0.4979 - accuracy: 0.7507\n",
      "Epoch 240/300\n",
      "603/603 [==============================] - 0s 704us/step - loss: 0.5031 - accuracy: 0.7490\n",
      "Epoch 241/300\n",
      "603/603 [==============================] - 0s 791us/step - loss: 0.5001 - accuracy: 0.7524\n",
      "Epoch 242/300\n",
      "603/603 [==============================] - 1s 832us/step - loss: 0.4976 - accuracy: 0.7520\n",
      "Epoch 243/300\n",
      "603/603 [==============================] - 0s 745us/step - loss: 0.4964 - accuracy: 0.7531\n",
      "Epoch 244/300\n",
      "603/603 [==============================] - 0s 632us/step - loss: 0.4972 - accuracy: 0.7516\n",
      "Epoch 245/300\n",
      "603/603 [==============================] - 0s 672us/step - loss: 0.5019 - accuracy: 0.7503\n",
      "Epoch 246/300\n",
      "603/603 [==============================] - 0s 729us/step - loss: 0.4956 - accuracy: 0.7531\n",
      "Epoch 247/300\n",
      "603/603 [==============================] - 0s 677us/step - loss: 0.4953 - accuracy: 0.7516\n",
      "Epoch 248/300\n",
      "603/603 [==============================] - 0s 652us/step - loss: 0.4966 - accuracy: 0.7485\n",
      "Epoch 249/300\n",
      "603/603 [==============================] - 0s 673us/step - loss: 0.5009 - accuracy: 0.7496\n",
      "Epoch 250/300\n",
      "603/603 [==============================] - 1s 916us/step - loss: 0.4957 - accuracy: 0.7527\n",
      "Epoch 251/300\n",
      "603/603 [==============================] - 0s 797us/step - loss: 0.4948 - accuracy: 0.7539\n",
      "Epoch 252/300\n",
      "603/603 [==============================] - 1s 915us/step - loss: 0.4910 - accuracy: 0.7557\n",
      "Epoch 253/300\n",
      "603/603 [==============================] - 0s 772us/step - loss: 0.4988 - accuracy: 0.7496\n",
      "Epoch 254/300\n",
      "603/603 [==============================] - 0s 659us/step - loss: 0.4937 - accuracy: 0.7521\n",
      "Epoch 255/300\n",
      "603/603 [==============================] - 0s 826us/step - loss: 0.4991 - accuracy: 0.7514\n",
      "Epoch 256/300\n",
      "603/603 [==============================] - 0s 772us/step - loss: 0.4985 - accuracy: 0.7502\n",
      "Epoch 257/300\n",
      "603/603 [==============================] - 0s 745us/step - loss: 0.4969 - accuracy: 0.7500\n",
      "Epoch 258/300\n",
      "603/603 [==============================] - 1s 866us/step - loss: 0.4938 - accuracy: 0.7511\n",
      "Epoch 259/300\n",
      "603/603 [==============================] - 1s 851us/step - loss: 0.4924 - accuracy: 0.7508\n",
      "Epoch 260/300\n",
      "603/603 [==============================] - 1s 836us/step - loss: 0.4959 - accuracy: 0.7489\n",
      "Epoch 261/300\n",
      "603/603 [==============================] - 1s 848us/step - loss: 0.4947 - accuracy: 0.7504\n",
      "Epoch 262/300\n",
      "603/603 [==============================] - 0s 745us/step - loss: 0.4949 - accuracy: 0.7529\n",
      "Epoch 263/300\n",
      "603/603 [==============================] - 0s 666us/step - loss: 0.4943 - accuracy: 0.7547\n",
      "Epoch 264/300\n",
      "603/603 [==============================] - 0s 659us/step - loss: 0.4937 - accuracy: 0.7511\n",
      "Epoch 265/300\n",
      "603/603 [==============================] - 0s 677us/step - loss: 0.4928 - accuracy: 0.7547\n",
      "Epoch 266/300\n",
      "603/603 [==============================] - 0s 652us/step - loss: 0.4885 - accuracy: 0.7565\n",
      "Epoch 267/300\n",
      "603/603 [==============================] - 0s 668us/step - loss: 0.4976 - accuracy: 0.7531\n",
      "Epoch 268/300\n",
      "603/603 [==============================] - 0s 648us/step - loss: 0.4925 - accuracy: 0.7507\n",
      "Epoch 269/300\n",
      "603/603 [==============================] - 0s 650us/step - loss: 0.4892 - accuracy: 0.7550\n",
      "Epoch 270/300\n",
      "603/603 [==============================] - 0s 731us/step - loss: 0.4928 - accuracy: 0.7509\n",
      "Epoch 271/300\n",
      "603/603 [==============================] - 0s 824us/step - loss: 0.4906 - accuracy: 0.7539\n",
      "Epoch 272/300\n",
      "603/603 [==============================] - 1s 842us/step - loss: 0.4924 - accuracy: 0.7527\n",
      "Epoch 273/300\n",
      "603/603 [==============================] - 1s 836us/step - loss: 0.4978 - accuracy: 0.7502\n",
      "Epoch 274/300\n",
      "603/603 [==============================] - 0s 706us/step - loss: 0.4873 - accuracy: 0.7551\n",
      "Epoch 275/300\n",
      "603/603 [==============================] - 0s 703us/step - loss: 0.4937 - accuracy: 0.7532\n",
      "Epoch 276/300\n",
      "603/603 [==============================] - 0s 734us/step - loss: 0.4894 - accuracy: 0.7553\n",
      "Epoch 277/300\n",
      "603/603 [==============================] - 0s 761us/step - loss: 0.4966 - accuracy: 0.7518\n",
      "Epoch 278/300\n",
      "603/603 [==============================] - 0s 755us/step - loss: 0.4906 - accuracy: 0.7551\n",
      "Epoch 279/300\n",
      "603/603 [==============================] - 0s 740us/step - loss: 0.4921 - accuracy: 0.7511\n",
      "Epoch 280/300\n",
      "603/603 [==============================] - 0s 717us/step - loss: 0.4924 - accuracy: 0.7546\n",
      "Epoch 281/300\n",
      "603/603 [==============================] - 0s 710us/step - loss: 0.4946 - accuracy: 0.7515\n",
      "Epoch 282/300\n",
      "603/603 [==============================] - 0s 728us/step - loss: 0.4943 - accuracy: 0.7519\n",
      "Epoch 283/300\n",
      "603/603 [==============================] - 0s 692us/step - loss: 0.4944 - accuracy: 0.7534\n",
      "Epoch 284/300\n",
      "603/603 [==============================] - 0s 679us/step - loss: 0.4914 - accuracy: 0.7554\n",
      "Epoch 285/300\n",
      "603/603 [==============================] - 0s 710us/step - loss: 0.4873 - accuracy: 0.7560\n",
      "Epoch 286/300\n",
      "603/603 [==============================] - 0s 735us/step - loss: 0.4864 - accuracy: 0.7544\n",
      "Epoch 287/300\n",
      "603/603 [==============================] - 0s 791us/step - loss: 0.4891 - accuracy: 0.7557\n",
      "Epoch 288/300\n",
      "603/603 [==============================] - 0s 776us/step - loss: 0.4917 - accuracy: 0.7554\n",
      "Epoch 289/300\n",
      "603/603 [==============================] - 0s 822us/step - loss: 0.4877 - accuracy: 0.7550\n",
      "Epoch 290/300\n",
      "603/603 [==============================] - 0s 787us/step - loss: 0.4852 - accuracy: 0.7573\n",
      "Epoch 291/300\n",
      "603/603 [==============================] - 1s 912us/step - loss: 0.4932 - accuracy: 0.7553\n",
      "Epoch 292/300\n",
      "603/603 [==============================] - 0s 751us/step - loss: 0.4892 - accuracy: 0.7571\n",
      "Epoch 293/300\n",
      "603/603 [==============================] - 0s 688us/step - loss: 0.4930 - accuracy: 0.7538\n",
      "Epoch 294/300\n",
      "603/603 [==============================] - 0s 678us/step - loss: 0.4876 - accuracy: 0.7549\n",
      "Epoch 295/300\n",
      "603/603 [==============================] - 0s 679us/step - loss: 0.4901 - accuracy: 0.7563\n",
      "Epoch 296/300\n",
      "603/603 [==============================] - 0s 702us/step - loss: 0.4892 - accuracy: 0.7583\n",
      "Epoch 297/300\n",
      "603/603 [==============================] - 0s 763us/step - loss: 0.4891 - accuracy: 0.7548\n",
      "Epoch 298/300\n",
      "603/603 [==============================] - 0s 758us/step - loss: 0.4894 - accuracy: 0.7554\n",
      "Epoch 299/300\n",
      "603/603 [==============================] - 0s 741us/step - loss: 0.4885 - accuracy: 0.7556\n",
      "Epoch 300/300\n",
      "603/603 [==============================] - 0s 748us/step - loss: 0.4882 - accuracy: 0.7547\n",
      "129/129 [==============================] - 0s 453us/step - loss: 1.0586 - accuracy: 0.6524\n",
      "[1.0585507154464722, 0.6523532271385193]\n",
      "129/129 [==============================] - 0s 437us/step\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.63      0.59      1672\n",
      "           1       0.73      0.67      0.70      2450\n",
      "\n",
      "    accuracy                           0.65      4122\n",
      "   macro avg       0.64      0.65      0.65      4122\n",
      "weighted avg       0.66      0.65      0.65      4122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "630f0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_class0 = df[df[\"HTO_classification.global\"] ==0]\n",
    "df3_class1 = df[df[\"HTO_classification.global\"] ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65784d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6800, 51), (13903, 51))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_class1.shape, df3_class0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e97a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b1f73c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[837 365]\n",
      " [311 890]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_true contains the true labels and y_pred contains the predicted labels\n",
    "# Replace y_true and y_pred with your actual true labels and predicted labels\n",
    "# Example:\n",
    "# y_true = [0, 1, 0, 1, 1]\n",
    "# y_pred = [0, 1, 1, 1, 0]\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de79858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8414042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7174b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
